{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/sd-notebook-collection/blob/main/cagliostro-colab-ui-pro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "![visitor][visitor-badge] \n",
        "[![discord][discord-badge]][discord-lookup]\n",
        "[![ko-fi][ko-fi-badge]][ko-fi-link]\n",
        "[![saweria][saweria-badge]][saweria-link]\n",
        "\n",
        "# [**Cagliostro Colab UI Pro**][link-to-github]\n",
        "All-in-One, Customizable and Flexible AUTOMATIC1111's Stable Diffusion Web UI for Google Colab.\n",
        "\n",
        "[What's New?][README] | `NEW!` [Pocketbook Guide][MANUAL]\n",
        "\n",
        "[visitor-badge]: https://visitor-badge.glitch.me/badge?page_id=linaqruf.cag-webui\n",
        "[discord-badge]: https://dcbadge.vercel.app/api/shield/850007095775723532?style=flat\n",
        "[discord-lookup]: https://lookup.guru/850007095775723532\n",
        "[ko-fi-badge]: https://img.shields.io/badge/Support%20me%20on%20Ko--fi-F16061?logo=ko-fi&logoColor=white&style=flat\n",
        "[ko-fi-link]: https://ko-fi.com/linaqruf\n",
        "[saweria-badge]: https://img.shields.io/badge/Saweria-7B3F00?style=flat&logo=ko-fi&logoColor=white\n",
        "[saweria-link]: https://saweria.co/linaqruf\n",
        "[link-to-github]: https://github.com/Linaqruf/sd-notebook-collection/blob/main/cagliostro-colab-ui-pro.ipynb\n",
        "[README]: https://github.com/Linaqruf/sd-notebook-collection/blob/main/README.md#whats-new\n",
        "[MANUAL]: https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#cagliostro-colab-ui-user-manual\n",
        "\n"
      ],
      "metadata": {
        "id": "WgQr3s96015a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Install Stable Diffusion Web UI** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#install-stable-diffusion-web-ui)</small></small>\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import time\n",
        "import json\n",
        "import fileinput\n",
        "from google.colab import drive\n",
        "from datetime import timedelta\n",
        "from subprocess import getoutput\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import clear_output, display, HTML\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "\n",
        "%store -r\n",
        "\n",
        "# root directory\n",
        "root_dir = \"/content\"\n",
        "repo_dir = os.path.join(root_dir, \"stable-diffusion-webui\")\n",
        "tmp_dir = os.path.join(root_dir, \"tmp\")\n",
        "patches_dir = os.path.join(root_dir, \"patches\")\n",
        "deps_dir = os.path.join(root_dir, \"deps\")\n",
        "fused_dir = os.path.join(root_dir, \"fused\")\n",
        "\n",
        "# repository directory\n",
        "outputs_dir = os.path.join(repo_dir, \"outputs\")\n",
        "models_dir = os.path.join(repo_dir, \"models/Stable-diffusion\")\n",
        "vaes_dir = os.path.join(repo_dir, \"models/VAE\")\n",
        "hypernetworks_dir = os.path.join(repo_dir, \"models/hypernetworks\")\n",
        "embeddings_dir = os.path.join(repo_dir, \"embeddings\")\n",
        "extensions_dir = os.path.join(repo_dir, \"extensions\")\n",
        "lora_dir = os.path.join(repo_dir, \"models/Lora\")\n",
        "control_dir = os.path.join(repo_dir, \"models/ControlNet\")\n",
        "esrgan_dir = os.path.join(repo_dir, \"models/ESRGAN\")\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    for dir in [ \"root_dir\", \"fused_dir\", \"repo_dir\", \"tmp_dir\", \"outputs_dir\", \"models_dir\", \"vaes_dir\", \"hypernetworks_dir\", \"embeddings_dir\", \"extensions_dir\", \"lora_dir\", \"control_dir\", \"esrgan_dir\"]:\n",
        "        %store {dir}\n",
        "    del cap\n",
        "    \n",
        "# url or path\n",
        "config_file = os.path.join(repo_dir, \"config.json\")\n",
        "webui_style_path = os.path.join(repo_dir, \"style.css\")\n",
        "\n",
        "# @markdown ### Drive Config\n",
        "mount_drive = False  # @param {type:'boolean'}\n",
        "output_to_drive = False  # @param {type:'boolean'}\n",
        "output_drive_folder = \"cagliostro-colab-ui/outputs\" #@param {type:'string'}\n",
        "\n",
        "# @markdown ### Web UI Config\n",
        "# @markdown > `anapnoe-webui` is a fork that provides better UI/UX\n",
        "use_anapnoe_ui = True  # @param {type:'boolean'}\n",
        "update_webui = True  # @param {type:'boolean'}\n",
        "update_extensions = True  # @param {type:'boolean'}\n",
        "commit_hash = \"\"  # @param {type:'string'}\n",
        "# @markdown > It's not recommended to set this `True` if you have **Colab Pro** subscription.\n",
        "colab_optimizations = False  # @param {type:'boolean'}\n",
        "\n",
        "\n",
        "# model\n",
        "os.chdir(root_dir)\n",
        "\n",
        "repo_type = \"webui\" if not use_anapnoe_ui else \"anapnoe-webui\"\n",
        "package_url = [\n",
        "    f\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/{repo_type}.tar.lz4\",\n",
        "    f\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/{repo_type}-deps.tar.lz4\",\n",
        "    f\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/{repo_type}-cache.tar.lz4\",\n",
        "]\n",
        "\n",
        "def ubuntu_deps(url, dst):\n",
        "    os.makedirs(dst, exist_ok=True)\n",
        "    filename = os.path.basename(url)\n",
        "    !wget -q --show-progress {url}\n",
        "    with zipfile.ZipFile(filename, \"r\") as deps:\n",
        "        deps.extractall(dst)\n",
        "    !dpkg -i {dst}/*\n",
        "    os.remove(filename)\n",
        "    shutil.rmtree(dst)\n",
        "\n",
        "def pre_download(desc, overwrite=False):\n",
        "    for package in tqdm(package_url, desc=desc):\n",
        "        with capture.capture_output() as cap:\n",
        "            package_name = os.path.basename(package)\n",
        "            !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {root_dir} -o {package_name} {package}\n",
        "            if package_name == f\"{repo_type}-deps.tar.lz4\":\n",
        "                !tar -xI lz4 -f {package_name} --overwrite-dir --directory=/usr/local/lib/python3.9/dist-packages/\n",
        "            else:\n",
        "                !tar -xI lz4 -f {package_name} {\"--overwrite-dir\" if overwrite else \"\"} --directory=/\n",
        "            os.remove(package_name)\n",
        "            del cap\n",
        "\n",
        "    if os.path.exists(\"/usr/local/lib/python3.9/dist-packages/ffmpy-0.3.0.dist-info\"):\n",
        "        shutil.rmtree(\"/usr/local/lib/python3.9/dist-packages/ffmpy-0.3.0.dist-info\")\n",
        "\n",
        "    s = getoutput(\"nvidia-smi\")\n",
        "    with capture.capture_output() as cap:\n",
        "        if not \"T4\" in s:\n",
        "            !pip uninstall -y xformers\n",
        "            !pip install -q xformers==0.0.18\n",
        "        del cap\n",
        "\n",
        "    !git config --global user.email \"you@example.com\"\n",
        "    !git config --global user.name \"Your Name\"\n",
        "\n",
        "def read_config(filename):\n",
        "    if filename.endswith(\".json\"):\n",
        "        with open(filename, \"r\") as f:\n",
        "          config = json.load(f)\n",
        "    else:\n",
        "        with open(filename, 'r') as f:\n",
        "          config = f.read()\n",
        "    return config\n",
        "\n",
        "def write_config(filename, config):\n",
        "    if filename.endswith(\".json\"):\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(config, f, indent=4)\n",
        "    else:\n",
        "        with open(filename, 'w', encoding=\"utf-8\") as f:\n",
        "            f.write(config)\n",
        "\n",
        "def install_dependencies():\n",
        "    ubuntu_deps_url = \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/ubuntu-deps.zip\"\n",
        "    ram_patch = \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/ram_patch.zip\"\n",
        "\n",
        "    print(\"\u001b[1;32mInstalling dependencies...\")\n",
        "    \n",
        "    with capture.capture_output() as cap:\n",
        "        !apt -y update -qq\n",
        "        !apt install libunwind8-dev -yqq\n",
        "        !apt install unionfs-fuse -qq\n",
        "        for url in [ubuntu_deps_url, ram_patch]:\n",
        "            ubuntu_deps(url, deps_dir)\n",
        "        os.environ[\"LD_PRELOAD\"] = \"libtcmalloc.so\"\n",
        "        del cap   \n",
        "\n",
        "def install_webui(overwrite):\n",
        "    desc = \"\u001b[1;32mUnpacking Webui\"\n",
        "    if use_anapnoe_ui:\n",
        "        print(\"\u001b[1;32mUsing new UI/UX from @Anapnoe...\")\n",
        "    pre_download(desc, overwrite)\n",
        "\n",
        "    for dir in [fused_dir, models_dir, vaes_dir, hypernetworks_dir, embeddings_dir, extensions_dir, lora_dir, control_dir, esrgan_dir]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "def reinstall_webui():\n",
        "    os.chdir(repo_dir)\n",
        "    try:\n",
        "        with capture.capture_output() as cap:\n",
        "            !git remote -v\n",
        "    except Exception as e:\n",
        "        print(f\"\u001b[1;32mAn error occurred: {e}\")\n",
        "\n",
        "    output = cap.stdout.strip()\n",
        "    os.chdir(root_dir)\n",
        "    try:\n",
        "        if use_anapnoe_ui:\n",
        "          if \"https://github.com/anapnoe/stable-diffusion-webui-ux\" in output:\n",
        "              print(\"\u001b[1;32mAlready installed, skipping...\")\n",
        "          else:\n",
        "            print(\"\u001b[1;32mReinstall Web UI, use Anapnoe version...\")\n",
        "            install_webui(overwrite=True)\n",
        "        else:\n",
        "          if \"https://github.com/AUTOMATIC1111/stable-diffusion-webui\" in output:\n",
        "              print(\"\u001b[1;32mAlready installed, skipping...\")\n",
        "          else:\n",
        "            print(\"\u001b[1;32mReinstall Web UI, use Automatic1111 version...\")\n",
        "            install_webui(overwrite=True)\n",
        "    except Exception as e:\n",
        "        print(f\"\u001b[1;32mAn error occurred: {e}\")\n",
        "            \n",
        "def main():\n",
        "    global drive_dir\n",
        "    \n",
        "    start_time = time.time()\n",
        "\n",
        "    if mount_drive:\n",
        "        if not os.path.exists(\"/content/drive/MyDrive\"):\n",
        "            print(\"\u001b[1;32mMounting google drive...\")\n",
        "            drive.mount(\"/content/drive\")\n",
        "          \n",
        "    install_dependencies()\n",
        "\n",
        "    if not os.path.exists(repo_dir):\n",
        "        install_webui(overwrite=False)\n",
        "    else:\n",
        "        reinstall_webui()\n",
        "\n",
        "    if commit_hash:\n",
        "        try:\n",
        "            os.chdir(repo_dir)\n",
        "            with capture.capture_output() as cap:\n",
        "                !git reset --hard {commit_hash}\n",
        "                del cap\n",
        "            print(\"\u001b[1;32mCommit hash: \", commit_hash)\n",
        "        except Exception as e:\n",
        "            print(\"\u001b[1;32mAn error occurred while resetting the commit hash:\", e)\n",
        "\n",
        "    if update_webui:\n",
        "        try:\n",
        "            print(\"\u001b[1;32mUpdating Web UI to the latest version\")\n",
        "            with capture.capture_output() as cap:\n",
        "                os.chdir(repo_dir)\n",
        "                !git pull -X theirs --rebase --autostash\n",
        "            del cap\n",
        "        except Exception as e:\n",
        "            print(\"\u001b[1;32mAn error occurred when updating Web UI:\", e)\n",
        "\n",
        "    if colab_optimizations:\n",
        "        sdv2_patches = \"https://raw.githubusercontent.com/ddPn08/automatic1111-colab/main/patches/stablediffusion-lowram.patch\"\n",
        "        with capture.capture_output() as cap:\n",
        "            os.makedirs(patches_dir, exist_ok=True)\n",
        "            !wget  {sdv2_patches} -P {patches_dir}  -c\n",
        "            os.chdir(os.path.join(repo_dir, \"repositories/stable-diffusion-stability-ai\"))\n",
        "            !git apply {patches_dir}/stablediffusion-lowram.patch\n",
        "            del cap\n",
        "        !sed -i \"s@os.path.splitext(checkpoint_.*@os.path.splitext(checkpoint_file); map_location='cuda'@\" {repo_dir}/modules/sd_models.py\n",
        "        !sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' {repo_dir}/webui.py\n",
        "        !sed -i \"s@'cpu'@'cuda'@\" {repo_dir}/modules/extras.py\n",
        "        shutil.rmtree(patches_dir)\n",
        "\n",
        "    if output_to_drive: \n",
        "        if not os.path.exists(\"/content/drive/MyDrive\"):\n",
        "            print(\"\u001b[1;32mMounting google drive...\")\n",
        "            drive.mount(\"/content/drive\")\n",
        "        drive_dir = os.path.join(\"/content/drive/MyDrive\", output_drive_folder)\n",
        "        print(\"\u001b[1;32mSet default output path to:\", drive_dir)\n",
        "    else:\n",
        "        drive_dir = outputs_dir\n",
        "    \n",
        "    os.makedirs(drive_dir, exist_ok=True)\n",
        "    with capture.capture_output() as cap:\n",
        "        %store drive_dir\n",
        "        del cap\n",
        "\n",
        "    config = read_config(config_file)\n",
        "    config[\"outdir_txt2img_samples\"] = os.path.join(drive_dir, \"txt2img-images\")\n",
        "    config[\"outdir_img2img_samples\"] = os.path.join(drive_dir, \"img2img-images\")\n",
        "    config[\"outdir_extras_samples\"] = os.path.join(drive_dir, \"extras-images\")\n",
        "    config[\"outdir_txt2img_grids\"] = os.path.join(drive_dir, \"txt2img-grids\")\n",
        "    config[\"outdir_img2img_grids\"] = os.path.join(drive_dir, \"img2img-grids\")\n",
        "    write_config(config_file, config)\n",
        "\n",
        "    skipped_extensions = []\n",
        "\n",
        "    if use_anapnoe_ui:\n",
        "        skipped_extensions = [\"stable-diffusion-webui-images-browser\"]\n",
        "        for filename in os.listdir(extensions_dir):\n",
        "            if \"stable-diffusion-webui\" in filename:\n",
        "                config = read_config(config_file)\n",
        "                if not \"stable-diffusion-webui\" in config[\"disabled_extensions\"]:\n",
        "                    config[\"disabled_extensions\"].append(\"stable-diffusion-webui\")\n",
        "                write_config(config_file, config)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = int(end_time - start_time)\n",
        "\n",
        "    if elapsed_time < 60:\n",
        "        print(f\"\u001b[1;32mFinished unpacking. Took {elapsed_time} sec\")\n",
        "    else:\n",
        "        mins, secs = divmod(elapsed_time, 60)\n",
        "        print(f\"\u001b[1;32mFinished unpacking. Took {mins} mins {secs} sec\")\n",
        "\n",
        "    if update_extensions:\n",
        "        start_time = time.time()\n",
        "        extensions_updated = []\n",
        "        extensions_list = os.listdir(extensions_dir)\n",
        "        with tqdm(\n",
        "            total=len(extensions_list) - len(skipped_extensions) - 1,\n",
        "            desc=\"\u001b[1;32mUpdating extensions\",\n",
        "            mininterval=0,\n",
        "        ) as pbar:\n",
        "            for dir in os.listdir(extensions_dir):\n",
        "                if os.path.isdir(os.path.join(extensions_dir, dir)):\n",
        "                    os.chdir(os.path.join(extensions_dir, dir))\n",
        "                    if dir not in skipped_extensions:\n",
        "                        try:\n",
        "                            with capture.capture_output() as cap:\n",
        "                                !git fetch origin\n",
        "                                !git pull\n",
        "                        except Exception as e:\n",
        "                            print(f\"\u001b[1;32mAn error occurred while updating {dir}: {e}\")\n",
        "                            \n",
        "                        output = cap.stdout.strip()\n",
        "                        if \"Already up to date.\" not in output:\n",
        "                            extensions_updated.append(dir)\n",
        "                        pbar.update(1)\n",
        "\n",
        "        for ext in extensions_updated:\n",
        "            print(f\"\u001b[1;32m- {ext} updated to new version\")\n",
        "        for ext in skipped_extensions:\n",
        "            print(f\"\u001b[1;32m- {ext} skipped\")\n",
        "\n",
        "        end_time = time.time()\n",
        "        elapsed_time = int(end_time - start_time)\n",
        "\n",
        "        if elapsed_time < 60:\n",
        "            print(f\"\u001b[1;32mAll extensions are up to date. Took {elapsed_time} sec\")\n",
        "        else:\n",
        "            mins, secs = divmod(elapsed_time, 60)\n",
        "            print(f\"\u001b[1;32mAll extensions are up to date. Took {mins} mins {secs} sec\")\n",
        "\n",
        "    os.environ[\"colab_url\"] = eval_js(\"google.colab.kernel.proxyPort(7860, {'cache': false})\")\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "    print(\"\u001b[1;32mAll is done! Go to the next step.\")\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "A6c7-qjDdb0X",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Model and VAE** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#download-model-and-vae)</small></small>\n",
        "import os\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# @markdown ### Available SD v1.x Model\n",
        "anything_v3_0 = False  # @param {type: 'boolean'}\n",
        "anime_pastel_dream = False  # @param {type: 'boolean'}\n",
        "anylora = True  # @param {type: 'boolean'}\n",
        "chilloutmix_ni = False  # @param {type: 'boolean'}\n",
        "# @markdown ### Available SD v2.x 768v Model\n",
        "replicant_v2 = False  # @param {type: 'boolean'}\n",
        "waifu_diffusion_v1_5_e2_aesthetic = False  # @param {type: 'boolean'}\n",
        "# @markdown ### Available VAE\n",
        "anime = True  # @param {type: 'boolean'}\n",
        "waifu_diffusion = False  # @param {type: 'boolean'}\n",
        "stable_diffusion = False  # @param {type: 'boolean'}\n",
        "\n",
        "downloadModels = []\n",
        "downloadVAE = []\n",
        "\n",
        "models = [\n",
        "    (\"anything_v3_0\", \"https://huggingface.co/AdamOswald1/Anything-Preservation/resolve/4121e81acc47bb87e46480ba1344b5ab57134b88/Anything-V3.0-pruned.safetensors\"),\n",
        "    (\"anime_pastel_dream\", \"https://huggingface.co/Lykon/AnimePastelDream/resolve/main/AnimePastelDream_Soft_noVae_fp16.safetensors\"),\n",
        "    (\"anylora\", \"https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16.safetensors\"),\n",
        "    (\"chilloutmix_ni\", \"https://huggingface.co/naonovn/chilloutmix_NiPrunedFp32Fix/resolve/main/chilloutmix_NiPrunedFp32Fix.safetensors\"),\n",
        "    (\"replicant_v2\", \"https://huggingface.co/gsdf/Replicant-V2.0/resolve/main/Replicant-V2.0_fp16.safetensors\"),\n",
        "    (\"waifu_diffusion_v1_5_e2_aesthetic\", \"https://huggingface.co/waifu-diffusion/wd-1-5-beta2/resolve/main/checkpoints/wd-1-5-beta2-aesthetic-fp16.safetensors\"),\n",
        "]\n",
        "\n",
        "vaeList = [\n",
        "    (\"anime\", \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\"),\n",
        "    (\"waifu_diffusion\", \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\"),\n",
        "    (\"stable_diffusion\", \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\"),\n",
        "]\n",
        "\n",
        "for model, url in models:\n",
        "    if locals()[model]:  # if checkbox is checked\n",
        "        downloadModels.append((model, url))\n",
        "\n",
        "for vae, url in vaeList:\n",
        "    if locals()[vae]:  # if checkbox is checked\n",
        "        downloadVAE.append((vae, url))\n",
        "\n",
        "def download(checkpoint_name, url, is_vae=None, is_control=None):\n",
        "    basename = os.path.basename(url)\n",
        "    hf_token = \"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\"\n",
        "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "    if is_vae:\n",
        "        !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {vaes_dir} -o {checkpoint_name}.vae.pt {url}\n",
        "    else:\n",
        "        if url.startswith(\"https://huggingface.co/\"):\n",
        "            ext = \"ckpt\" if url.endswith(\".ckpt\") else \"safetensors\"\n",
        "            !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {models_dir} -o {checkpoint_name}.{ext} {url}\n",
        "        else:\n",
        "            !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {models_dir} {url}\n",
        "\n",
        "def main():\n",
        "    downloaded_model = []\n",
        "    downloaded_vae = []\n",
        "\n",
        "    for model in tqdm(downloadModels, desc=\"\u001b[1;32mDownloading Models\"):\n",
        "        with capture.capture_output() as cap:\n",
        "            download(model[0], model[1], is_vae=False)\n",
        "            downloaded_model.append(model[0])\n",
        "            del cap\n",
        "\n",
        "    for vae in tqdm(downloadVAE, desc=\"\u001b[1;32mDownloading VAE\"):\n",
        "        with capture.capture_output() as cap:\n",
        "            download(vae[0], vae[1], is_vae=True)\n",
        "            downloaded_vae.append(vae[0])\n",
        "            del cap\n",
        "\n",
        "print(f\"\u001b[1;32mDownloading...\")\n",
        "start_time = time.time()\n",
        "\n",
        "main()\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = int(end_time - start_time)\n",
        "\n",
        "if elapsed_time < 60:\n",
        "    print(f\"\\n\u001b[1;32mDownload completed. Took {elapsed_time} sec\")\n",
        "else:\n",
        "    mins, secs = divmod(elapsed_time, 60)\n",
        "    print(f\"\\n\u001b[1;32mDownload completed. Took {mins} mins {secs} sec\")\n",
        "\n",
        "print(\"\u001b[1;32mAll is done! Go to the next step\")\n"
      ],
      "metadata": {
        "id": "qgvihy5BQ3II",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **ControlNet v1.1** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#controlnet-v11)</small></small>\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "import yaml\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse, unquote\n",
        "from datetime import timedelta\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "\n",
        "# @markdown ### ControlNet Annotator\n",
        "pre_download_annotator = True  # @param {type: 'boolean'}\n",
        "# @markdown ### SDv1.x ControlNet Model\n",
        "control_v11_sd15_model = True  # @param {type: 'boolean'}\n",
        "t2i_adapter_sd15_model = False  # @param {type: 'boolean'}\n",
        "# @markdown ### SDv2.x ControlNet Model\n",
        "control_v10_sd21_model = False  # @param {type: 'boolean'}\n",
        "control_v10_wd15_model = False  # @param {type: 'boolean'}\n",
        "# @markdown ### ControlNet Config:\n",
        "control_net_max_models_num = 2 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "control_net_model_adapter_config = \"sketch_adapter_v14.yaml\" #@param [\"image_adapter_v14.yaml\", \"sketch_adapter_v14.yaml\", \"t2iadapter_color_sd14v1.yaml\", \"t2iadapter_keypose_sd14v1.yaml\", \"t2iadapter_style_sd14v1.yaml\"]\n",
        "config_file = os.path.join(repo_dir, \"config.json\")\n",
        "\n",
        "annotator_dict = {\n",
        "    \"oneformer\"     : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/150_16_swin_l_oneformer_coco_100ep.pth\",\n",
        "    \"oneformer\"     : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/250_16_swin_l_oneformer_ade20k_160k.pth\",\n",
        "    \"zoedepth\"      : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/ZoeD_M12_N.pt\",\n",
        "    \"midas\"         : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/dpt_beit_large_512.pt\",\n",
        "    \"midas\"         : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/dpt_hybrid-midas-501f0c75.pt\",\n",
        "    \"midas\"         : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/dpt_large-midas-2f21e586.pt\",\n",
        "    \"openpose\"      : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/facenet.pth\",\n",
        "    \"openpose\"      : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/hand_pose_model.pth\",\n",
        "    \"openpose\"      : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/body_pose_model.pth\",\n",
        "    \"keypose\"       : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\",\n",
        "    \"keypose\"       : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth\",\n",
        "    \"leres\"         : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/latest_net_G.pth\",\n",
        "    \"leres\"         : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/res101.pth\",\n",
        "    \"mlsd\"          : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/mlsd_large_512_fp32.pth\",\n",
        "    \"lineart_anime\" : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/netG.pth\",\n",
        "    \"hed\"           : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/network-bsds500.pth\",\n",
        "    \"normal_bae\"    : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/scannet.pt\",\n",
        "    \"lineart\"       : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/sk_model.pth\",\n",
        "    \"lineart\"       : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/sk_model2.pth\",\n",
        "    \"pidinet\"       : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/table5_pidinet.pth\",\n",
        "    \"uniformer\"     : \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/upernet_global_small.pth\",\n",
        "}\n",
        "\n",
        "control_v11_sd15_url = [\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_depth_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_scribble_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_seg_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11u_sd15_tile_fp16.safetensors\",\n",
        "]\n",
        "\n",
        "t2i_adapter_sd15_url = [\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_style_sd14v1.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_sketch_sd14v1.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_seg_sd14v1.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_openpose_sd14v1.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_keypose_sd14v1.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_depth_sd14v1.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_color_sd14v1.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_canny_sd14v1.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_canny_sd15v2.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_depth_sd15v2.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_sketch_sd15v2.pth\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_zoedepth_sd15v1.pth\",\n",
        "]\n",
        "\n",
        "control_v10_sd21_url = [\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/canny-sd21-safe.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/depth-sd21-safe.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/hed-sd21-safe.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/openpose-sd21-safe.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/scribble-sd21-safe.safetensors\",\n",
        "]\n",
        "\n",
        "control_v10_wd15_url = [\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/diff_control_wd15beta2_canny.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/diff_control_wd15beta2_depth.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet/resolve/main/diff_control_wd15beta2_pose.safetensors\",\n",
        "]\n",
        "\n",
        "def read_config(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        config = json.load(f)\n",
        "    return config\n",
        "\n",
        "def write_config(filename, config):\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(config, f, indent=4)\n",
        "\n",
        "def cldm_config_path(destination_path):\n",
        "    if \"_sd15_\" in destination_path or \"_sd15s2_\" in destination_path:\n",
        "        return \"cldm_v15.yaml\"\n",
        "    elif \"-sd21-\" in destination_path or \"_wd15beta2_\" in destination_path: \n",
        "        return \"cldm_v21.yaml\"\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def cldm_config(destination_path):\n",
        "    control_net_model_config = cldm_config_path(destination_path)\n",
        "    if control_net_model_config is not None:\n",
        "        cldm_config_src = os.path.join(extensions_dir, os.path.join(\"sd-webui-controlnet/models\", control_net_model_config))\n",
        "        cldm_config_dst = os.path.splitext(destination_path)[0] + \".yaml\"\n",
        "        if \"_shuffle_\" in cldm_config_dst:\n",
        "            cldm_config_src = os.path.join(extensions_dir, \"sd-webui-controlnet/models/control_v11e_sd15_shuffle.yaml\")\n",
        "        if not os.path.exists(cldm_config_dst):\n",
        "            shutil.copy(cldm_config_src, cldm_config_dst)\n",
        "\n",
        "def download(url, destination_path, is_annotator=None):\n",
        "    hf_token = \"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\"\n",
        "    user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "    basename = os.path.basename(url)\n",
        "    dst_dir = os.path.join(os.path.dirname(control_dir), destination_path) if is_annotator else destination_path\n",
        "    os.makedirs(dst_dir, exist_ok=True)\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {dst_dir} -o {basename} {url}\n",
        "    cldm_config(os.path.join(dst_dir, basename))\n",
        "\n",
        "def batch(url, download_description, is_annotator=None):\n",
        "    if is_annotator:\n",
        "        for dest_path, url in tqdm(annotator_dict.items(), desc=f\"\u001b[1;32mDownloading {download_description}\"):\n",
        "            with capture.capture_output() as cap:\n",
        "                download(url, dest_path, is_annotator=True)\n",
        "                del cap\n",
        "    else:\n",
        "        for control in tqdm(url, desc=f\"\u001b[1;32mDownloading {download_description}\"):\n",
        "            with capture.capture_output() as cap:\n",
        "                download(control, control_dir, is_annotator=False)\n",
        "                del cap\n",
        "\n",
        "def main():\n",
        "    config = read_config(config_file)\n",
        "    config[\"control_net_max_models_num\"] = control_net_max_models_num\n",
        "    config[\"control_net_models_path\"] = control_dir\n",
        "    config[\"control_net_model_adapter_config\"] = os.path.join(extensions_dir, os.path.join(\"sd-webui-controlnet/models\", control_net_model_adapter_config))\n",
        "    config[\"control_net_allow_script_control\"] = True\n",
        "    write_config(config_file, config)\n",
        "  \n",
        "    if pre_download_annotator:\n",
        "        batch(annotator_dict, \n",
        "              \"ControlNet Annotator/Preprocessor\", \n",
        "              is_annotator=True)\n",
        "              \n",
        "    if control_v11_sd15_model:\n",
        "        batch(control_v11_sd15_url, \n",
        "              \"SDv1.x ControlNet Model\", \n",
        "              is_annotator=False)\n",
        "        \n",
        "    if t2i_adapter_sd15_model:\n",
        "        batch(t2i_adapter_sd15_url, \n",
        "              \"SDv1.x Text2Image Adapter Model\", \n",
        "              is_annotator=False)\n",
        "    \n",
        "    if control_v10_sd21_model:\n",
        "        batch(control_v10_sd21_url, \n",
        "              \"SDv2.x ControlNet Model\", \n",
        "              is_annotator=False)\n",
        "    \n",
        "    if control_v10_wd15_model:\n",
        "        batch(control_v10_wd15_url, \n",
        "              \"WD1.5 ControlNet Model\", \n",
        "              is_annotator=False)\n",
        "        \n",
        "print(f\"\u001b[1;32mDownloading...\")\n",
        "start_time = time.time()\n",
        "\n",
        "main()\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = int(end_time - start_time)\n",
        "\n",
        "if elapsed_time < 60:\n",
        "    print(f\"\\n\u001b[1;32mDownload completed. Took {elapsed_time} sec\")\n",
        "else:\n",
        "    mins, secs = divmod(elapsed_time, 60)\n",
        "    print(f\"\\n\u001b[1;32mDownload completed. Took {mins} mins {secs} sec\")\n",
        "\n",
        "print(\"\u001b[1;32mAll is done! Go to the next step\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LKKtxDoIIg1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Custom Download Corner** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#custom-download-corner)</small></small>\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import glob\n",
        "import requests\n",
        "import gc\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from datetime import timedelta\n",
        "from urllib.parse import urlparse, unquote\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "from safetensors.torch import load_file, save_file\n",
        "from torch import load, save\n",
        "import pickle as python_pickle\n",
        "\n",
        "%store -r\n",
        "\n",
        "# @markdown Fill in the URL fields with the links to the files you want to download. Separate multiple URLs with a comma.\n",
        "# @markdown Example: `url1, url2, url3`\n",
        "os.chdir(root_dir)\n",
        "\n",
        "custom_model_url = \"\"  # @param {'type': 'string'}\n",
        "custom_vae_url = \"\"  # @param {'type': 'string'}\n",
        "custom_embedding_url = \"\"  # @param {'type': 'string'}\n",
        "custom_LoRA_url = \"\"  # @param {'type': 'string'}\n",
        "custom_hypernetwork_url = \"\"  # @param {'type': 'string'}\n",
        "custom_extensions_url = \"\"  # @param {'type': 'string'}\n",
        "custom_upscaler_url = \"\"  # @param {'type': 'string'}\n",
        "\n",
        "custom_download_list = []\n",
        "\n",
        "custom_dirs = {\n",
        "    \"model\"       : models_dir,\n",
        "    \"vae\"         : vaes_dir,\n",
        "    \"embedding\"   : embeddings_dir,\n",
        "    \"LoRA\"        : lora_dir,\n",
        "    \"hypernetwork\": hypernetworks_dir,\n",
        "    \"extensions\"  : extensions_dir,\n",
        "    \"upscaler\"    : esrgan_dir,    \n",
        "}\n",
        "\n",
        "def is_safetensors(path):\n",
        "    return os.path.splitext(path)[1].lower() == '.safetensors'\n",
        "\n",
        "def extract(url, dst):\n",
        "    if not url.startswith(\"/content/\"):\n",
        "        filename = os.path.basename(url)\n",
        "        zipfile = os.path.join(dst, filename)\n",
        "    else:\n",
        "        zipfile = url\n",
        "\n",
        "    if url.endswith(\".zip\"):\n",
        "        if os.path.exists(zipfile):\n",
        "            !unzip -j -o {zipfile} -d \"{dst}\"\n",
        "            os.remove(zipfile)\n",
        "    elif url.endswith(\".tar.lz4\"):\n",
        "        if os.path.exists(zipfile):\n",
        "            !tar -xI lz4 -f {zipfile} --directory={dst}\n",
        "            os.remove(zipfile)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "def unionfuse(folder_path, dst_dir):\n",
        "    try:\n",
        "        if \"extensions\" in category:\n",
        "            print(f\"\\n\u001b[1;32m{category.capitalize()} folder can't be fused, skipping...\")\n",
        "        else: \n",
        "            category_dir = os.path.join(os.path.join(root_dir,\"fused\"), category)\n",
        "            for dir in [folder_path, category_dir, dst_dir]:\n",
        "                os.makedirs(dir, exist_ok=True)\n",
        "            with capture.capture_output() as cap:    \n",
        "                !unionfs-fuse {dst_dir}=RW:\"{folder_path}\"=RW {category_dir}\n",
        "            output = cap.stdout.strip()\n",
        "            if \"fuse: mountpoint is not empty\" in output:\n",
        "                print(f\"\\n\u001b[1;32m{category.capitalize()} folder is not empty and can't be fused, skipping...\")\n",
        "            else:\n",
        "                print(f\"\\n\u001b[1;32m{category.capitalize()} folder fused successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n\u001b[1;32mAn error occurred while fusing the folders: {e}\")\n",
        "\n",
        "def prune_model(checkpoint, fp16=False, ema=False, clip=True, vae=True, depth=True, unet=True):\n",
        "    # Borrowed Lopho's code hehe\n",
        "    sd = checkpoint\n",
        "    nested_sd = False\n",
        "    if 'state_dict' in sd:\n",
        "        sd = sd['state_dict']\n",
        "        nested_sd = True\n",
        "    sd_pruned = dict()\n",
        "    for k in sd:\n",
        "        cp = unet and k.startswith('model.diffusion_model.')\n",
        "        cp = cp or (depth and k.startswith('depth_model.'))\n",
        "        cp = cp or (vae and k.startswith('first_stage_model.'))\n",
        "        cp = cp or (clip and k.startswith('cond_stage_model.'))\n",
        "        if cp:\n",
        "            k_in = k\n",
        "            if ema:\n",
        "                k_ema = 'model_ema.' + k[6:].replace('.', '')\n",
        "                if k_ema in sd:\n",
        "                    k_in = k_ema\n",
        "            sd_pruned[k] = sd[k_in].half() if fp16 else sd[k_in]\n",
        "    del sd\n",
        "\n",
        "    if nested_sd:\n",
        "        return {'state_dict': sd_pruned}\n",
        "    else:\n",
        "        return sd_pruned\n",
        "\n",
        "def autoprune(model_path, prefix):\n",
        "    def bytes_to_gb(size_in_bytes):\n",
        "        return size_in_bytes / (1024 * 1024 * 1024)\n",
        "\n",
        "    initial_size = bytes_to_gb(os.path.getsize(model_path))\n",
        "\n",
        "    print(f\"\\n\u001b[1;32mPruning model ({prefix}): {model_path} ({initial_size:.2f} GB)\")\n",
        "    if is_safetensors(model_path):\n",
        "        input_sd = load_file(model_path)\n",
        "    else:\n",
        "        input_sd = load(model_path)  # type: ignore\n",
        "\n",
        "    pruned = prune_model(input_sd, fp16=(prefix == \"fp16\"))\n",
        "\n",
        "    model_name, ext = os.path.splitext(model_path)\n",
        "    output_path = f\"{model_name}-{prefix}{ext}\"\n",
        "\n",
        "    if is_safetensors(model_path):\n",
        "        save_file(pruned, output_path)\n",
        "    else:\n",
        "        save(pruned, output_path)\n",
        "\n",
        "    if \"/content/drive/MyDrive/\" not in model_path:\n",
        "        os.remove(model_path)\n",
        "\n",
        "    del input_sd, pruned\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    final_size = bytes_to_gb(os.path.getsize(output_path))\n",
        "    print(f\"\u001b[1;32mPruning completed: {output_path} ({final_size:.2f} GB)\")\n",
        "\n",
        "def get_most_recent_file(directory):\n",
        "    files = glob.glob(os.path.join(directory, \"*\"))\n",
        "    if not files:\n",
        "        return None\n",
        "    most_recent_file = max(files, key=os.path.getmtime)\n",
        "    return most_recent_file\n",
        "\n",
        "def get_filename(url):\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    if 'content-disposition' in response.headers:\n",
        "        content_disposition = response.headers['content-disposition']\n",
        "        filename = re.findall('filename=\"?([^\"]+)\"?', content_disposition)[0]\n",
        "    else:\n",
        "        url_path = urlparse(url).path\n",
        "        filename = unquote(os.path.basename(url_path))\n",
        "        \n",
        "    return filename\n",
        "\n",
        "def download(url_list, dst_dir, is_extensions):\n",
        "    supported_extensions = [\".ckpt\", \".safetensors\", \".pt\", \".pth\"]\n",
        "\n",
        "    desc = f\"\u001b[1;32mDownloading Custom {category.capitalize()}\"\n",
        "    if category == \"extensions\":\n",
        "        desc = f\"\u001b[1;32mInstalling Custom {category.capitalize()}\"\n",
        "\n",
        "    for url in tqdm(url_list, desc=desc):\n",
        "        if url:\n",
        "            url = url.strip()\n",
        "            prune_prefix = None\n",
        "            if url.startswith(\"fp32:\"):\n",
        "                prune_prefix = \"fp32\"\n",
        "                url = url[5:].strip()\n",
        "            elif url.startswith(\"fp16:\"):\n",
        "                prune_prefix = \"fp16\"\n",
        "                url = url[5:].strip()\n",
        "                \n",
        "            if url.startswith(\"fuse:\"):\n",
        "                folder_path = url[5:].strip()\n",
        "                unionfuse(folder_path, dst_dir)\n",
        "            else:\n",
        "                custom_download_list.append(url)\n",
        "                if url.startswith(\"/content/drive/MyDrive/\") or url.endswith(tuple(supported_extensions)):\n",
        "                    basename = os.path.basename(url)\n",
        "                else:\n",
        "                    basename = get_filename(url)\n",
        "\n",
        "                with capture.capture_output() as cap:\n",
        "                    if is_extensions:\n",
        "                        os.chdir(extensions_dir)\n",
        "                        !git clone {url}\n",
        "                    elif url.startswith(\"/content/drive/MyDrive/\"):\n",
        "                        Path(os.path.join(dst_dir, basename)).write_bytes(Path(url).read_bytes())\n",
        "                    elif \"drive.google.com\" in url:\n",
        "                        if \"folders\" in url:\n",
        "                            !gdown --folder \"{url}\" -O {dst_dir} --fuzzy -c\n",
        "                        else:\n",
        "                            !gdown \"{url}\" -O {dst_dir} --fuzzy -c\n",
        "                    elif \"huggingface.co\" in url:\n",
        "                        if \"/blob/\" in url:\n",
        "                            url = url.replace(\"/blob/\", \"/resolve/\")\n",
        "                        hf_token = \"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\"\n",
        "                        user_header = f'\"Authorization: Bearer {hf_token}\"'\n",
        "                        !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {dst_dir} -o {basename} {url}\n",
        "                    elif any(url.endswith(extension) for extension in supported_extensions):\n",
        "                        !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {dst_dir} -o {basename} {url}\n",
        "                    else:\n",
        "                        !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {dst_dir} {url}\n",
        "\n",
        "                    extract(url, dst_dir)\n",
        "                del cap\n",
        "\n",
        "            if prune_prefix:\n",
        "                if \"model\" in category:\n",
        "                    try:\n",
        "                        if any(basename.endswith(extension) for extension in supported_extensions):\n",
        "                            model_path = os.path.join(dst_dir, basename)\n",
        "                            autoprune(model_path, prune_prefix)\n",
        "                        else:\n",
        "                            most_recent_file = get_most_recent_file(dst_dir)\n",
        "                            if most_recent_file is not None:\n",
        "                                autoprune(most_recent_file, prune_prefix)\n",
        "                    except Exception as e:\n",
        "                        print(f\"\\n\u001b[1;32mError pruning file: {e}\")\n",
        "                else:\n",
        "                    print(f\"\\n\u001b[1;32mOnly model can be pruned, skipping...\")\n",
        "\n",
        "print(f\"\u001b[1;32mDownloading...\")\n",
        "start_time = time.time()\n",
        "\n",
        "for category, custom_url in [\n",
        "    (\"model\", custom_model_url),\n",
        "    (\"vae\", custom_vae_url),\n",
        "    (\"embedding\", custom_embedding_url),\n",
        "    (\"LoRA\", custom_LoRA_url),\n",
        "    (\"hypernetwork\", custom_hypernetwork_url),\n",
        "    (\"extensions\", custom_extensions_url),\n",
        "    (\"upscaler\", custom_upscaler_url),\n",
        "]:\n",
        "    if custom_url:\n",
        "        urls = custom_url.split(\",\")\n",
        "        download(urls, custom_dirs[category], category == \"extensions\")\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = int(end_time - start_time)\n",
        "\n",
        "print()\n",
        "if elapsed_time < 60:\n",
        "    print(f\"\u001b[1;32mDownload completed. Took {elapsed_time} sec\")\n",
        "else:\n",
        "    mins, secs = divmod(elapsed_time, 60)\n",
        "    print(f\"\u001b[1;32mDownload completed. Took {mins} mins {secs} sec\")\n",
        "\n",
        "print(\"\u001b[1;32mAll is done! Go to the next step\")\n",
        "\n",
        "custom_download_list = []"
      ],
      "metadata": {
        "id": "PdjuRPcX0-Q2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaAJk33ppFw1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## **Start Stable Diffusion Web UI** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#start-stable-diffusion-web-ui)</small></small>\n",
        "import os\n",
        "import random\n",
        "import string\n",
        "%store -r \n",
        "\n",
        "# @markdown ### Alternative Tunnel\n",
        "# @markdown > Recommended Tunnels: `ngrok` > `cloudflared` > `remotemoe` > `localhostrun` > `googleusercontent` > `gradio`\n",
        "tunnel = \"multiple\" # @param ['none', 'multiple','cloudflared', 'localhostrun', 'remotemoe', \"googleusercontent\"]\n",
        "# @markdown > Get <b>your</b> token for ngrok [here](https://dashboard.ngrok.com/get-started/your-authtoken) \n",
        "ngrok_token = \"\" # @param {type: 'string'}\n",
        "ngrok_region = \"ap\" # @param [\"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "# @markdown ### Theme Selector\n",
        "theme = \"ogxBGreen\" # @param ['tron2', 'ogxCyanInvert', 'ogxBGreen', 'ogxRed', 'default', 'moonlight', 'd-230-52-94', 'backup', 'tron', 'ogxRedYellow', 'default_orange', 'ogxRedPurple', 'retrog', 'ogxCyan', 'fun', 'ogxGreen', 'default_cyan', 'Golde']\n",
        "# @markdown ### Arguments\n",
        "use_gradio_auth = False # @param {type: 'boolean'}\n",
        "accelerator = \"xformers\" # @param ['xformers', 'opt-sdp-attention', 'opt-split-attention']\n",
        "load_in_vram = True # @param {type: 'boolean'}\n",
        "quiet_mode = True # @param {type: 'boolean'}\n",
        "auto_select_model = False # @param {type: 'boolean'}\n",
        "auto_select_VAE = True # @param {type: 'boolean'}\n",
        "no_half_VAE = True # @param {type: 'boolean'}\n",
        "additional_arguments = \"--no-download-sd-model --gradio-queue\" #@param {type: 'string'}\n",
        "\n",
        "config_file = os.path.join(repo_dir, \"config.json\")\n",
        "ui_config_file = os.path.join(repo_dir, \"ui-config.json\")\n",
        "\n",
        "default_prompt = \"masterpiece, best quality,\"\n",
        "default_neg_prompt = \"(worst quality, low quality:1.4)\"\n",
        "default_sampler = \"DPM++ 2M Karras\"\n",
        "default_steps = 20\n",
        "default_width = 512\n",
        "default_height = 768\n",
        "default_denoising_strength = 0.55\n",
        "default_cfg_scale = 7\n",
        "\n",
        "user = \"cagliostro\"\n",
        "password = \"\".join(random.choices(string.ascii_letters + string.digits, k=6))\n",
        "\n",
        "def read_config(filename):\n",
        "    if filename.endswith(\".json\"):\n",
        "        with open(filename, \"r\") as f:\n",
        "          config = json.load(f)\n",
        "    else:\n",
        "        with open(filename, 'r') as f:\n",
        "          config = f.read()\n",
        "\n",
        "    return config\n",
        "\n",
        "def write_config(filename, config):\n",
        "    if filename.endswith(\".json\"):\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(config, f, indent=4)\n",
        "    else:\n",
        "        with open(filename, 'w', encoding=\"utf-8\") as f:\n",
        "            f.write(config)\n",
        "            f.close()  \n",
        "\n",
        "def open_theme(filename):\n",
        "    themes_folder = os.path.join(repo_dir, \"extensions-builtin/sd_theme_editor/themes\")\n",
        "    themes_file = os.path.join(themes_folder, f\"{filename}.css\")\n",
        "    webui_style_path = os.path.join(repo_dir, \"style.css\")\n",
        "\n",
        "    style_config = read_config(webui_style_path)\n",
        "    style_css_contents = style_config.split(\"/*BREAKPOINT_CSS_CONTENT*/\")[1]\n",
        "\n",
        "    theme_config = read_config(themes_file)\n",
        "    style_data = \":host{\" + theme_config + \"}\" + \"/*BREAKPOINT_CSS_CONTENT*/\" + style_css_contents\n",
        "    write_config(webui_style_path, style_data)\n",
        "\n",
        "def change_theme(filename):\n",
        "    try:\n",
        "        with capture.capture_output() as cap:\n",
        "            !git remote -v\n",
        "    except Exception as e:\n",
        "        print(f\"\u001b[1;32mAn error occurred: {e}\")\n",
        "\n",
        "    output = cap.stdout.strip()\n",
        "    if \"https://github.com/anapnoe/stable-diffusion-webui-ux\" in output:\n",
        "        open_theme(filename)\n",
        "    else:\n",
        "        print(\"You're not using Anapnoe UI/UX, skipping theme selecting...\\n\")    \n",
        "\n",
        "def is_dir_exist(cloned_dir, original_dir):\n",
        "    if os.path.exists(cloned_dir):\n",
        "        return cloned_dir \n",
        "    else:\n",
        "        return original_dir\n",
        "\n",
        "valid_ckpt_dir = is_dir_exist(os.path.join(fused_dir, \"model\"), models_dir)\n",
        "valid_vae_dir = is_dir_exist(os.path.join(fused_dir, \"vae\"), vaes_dir)\n",
        "valid_embedding_dir = is_dir_exist(os.path.join(fused_dir, \"embedding\"), embeddings_dir)\n",
        "valid_lora_dir = is_dir_exist(os.path.join(fused_dir, \"LoRA\"), lora_dir)\n",
        "valid_hypernetwork_dir = is_dir_exist(os.path.join(fused_dir, \"hypernetwork\"), hypernetworks_dir)\n",
        "\n",
        "if auto_select_model:\n",
        "    model_path = \"dummy.ckpt\"\n",
        "    models_list = os.listdir(valid_ckpt_dir)\n",
        "    model_files = [f for f in models_list if f.endswith(('.ckpt','.safetensors'))]\n",
        "    if model_files:\n",
        "        model_path = random.choice(model_files)\n",
        "\n",
        "if auto_select_VAE:\n",
        "    vae_path = \"dummy.pt\"\n",
        "    vaes_list = os.listdir(valid_vae_dir)\n",
        "    vae_files = [f for f in vaes_list if f.endswith('.vae.pt')]\n",
        "    if vae_files:\n",
        "        vae_path = random.choice(vae_files)\n",
        "\n",
        "# config.json\n",
        "config = read_config(config_file)\n",
        "config[\"additional_networks_extra_lora_path\"] = valid_lora_dir\n",
        "config[\"CLIP_stop_at_last_layers\"] = 2\n",
        "config[\"eta_noise_seed_delta\"] = 0\n",
        "config[\"show_progress_every_n_steps\"] = 10\n",
        "config[\"show_progressbar\"] = True\n",
        "if auto_select_model and os.path.exists(os.path.join(valid_ckpt_dir, model_path)):\n",
        "    config[\"sd_model_checkpoint\"] = model_path\n",
        "if auto_select_VAE and os.path.exists(os.path.join(valid_vae_dir, vae_path)):\n",
        "    config[\"sd_vae\"] = vae_path\n",
        "config[\"quicksettings\"] = \"sd_model_checkpoint, sd_vae, CLIP_stop_at_last_layers, use_old_karras_scheduler_sigmas, always_discard_next_to_last_sigma\"\n",
        "write_config(config_file, config)\n",
        "\n",
        "# ui-config.json\n",
        "# txt2img\n",
        "config = read_config(ui_config_file)\n",
        "config[\"txt2img/Prompt/value\"] = default_prompt\n",
        "config[\"txt2img/Negative prompt/value\"] = default_neg_prompt\n",
        "config[\"txt2img/Sampling method/value\"] = default_sampler\n",
        "config[\"txt2img/Sampling steps/value\"] = default_steps\n",
        "config[\"txt2img/Width/value\"] = default_width\n",
        "config[\"txt2img/Height/value\"] = default_height\n",
        "config[\"txt2img/Upscaler/value\"] = \"Latent (nearest-exact)\"\n",
        "config[\"txt2img/Denoising strength/value\"] = default_denoising_strength\n",
        "config[\"txt2img/CFG Scale/value\"] = default_cfg_scale\n",
        "\n",
        "# img2img\n",
        "config[\"img2img/Prompt/value\"] = default_prompt\n",
        "config[\"img2img/Negative prompt/value\"] = default_neg_prompt\n",
        "config[\"img2img/Sampling method/value\"] = default_sampler\n",
        "config[\"img2img/Sampling steps/value\"] = default_steps\n",
        "config[\"img2img/Width/value\"] = default_width\n",
        "config[\"img2img/Height/value\"] = default_height\n",
        "config[\"img2img/Denoising strength/value\"] = default_denoising_strength\n",
        "config[\"img2img/CFG Scale/value\"] = default_cfg_scale\n",
        "write_config(ui_config_file, config)\n",
        "          \n",
        "os.chdir(repo_dir)\n",
        "change_theme(theme)\n",
        "\n",
        "print(\"\u001b[1;32m\")\n",
        "\n",
        "if use_gradio_auth:\n",
        "      print(\"Gradio Auth (use this account to login):\")\n",
        "      print(\"- Username: cagliostro\")\n",
        "      print(\"- Password:\", password)\n",
        "      print(\"\\n\\n\")\n",
        "\n",
        "config = {\n",
        "    \"enable-insecure-extension-access\": True,\n",
        "    \"disable-safe-unpickle\": True,\n",
        "    f\"{accelerator}\": True,\n",
        "    f\"{tunnel}\": True if not tunnel == \"none\" and not ngrok_token else False,\n",
        "    \"share\": True if not ngrok_token else False,\n",
        "    \"gradio-auth\": f\"{user}:{password}\" if use_gradio_auth else None,\n",
        "    \"no-half-vae\": no_half_VAE,\n",
        "    \"lowram\": load_in_vram,\n",
        "    \"no-hashing\": quiet_mode,\n",
        "    \"disable-console-progressbars\": quiet_mode,\n",
        "    \"ngrok\": ngrok_token if ngrok_token else None,\n",
        "    \"ngrok-region\": ngrok_region if ngrok_token else None,\n",
        "    \"opt-sub-quad-attention\": True,\n",
        "    \"opt-channelslast\": True,\n",
        "    \"theme\": \"dark\",\n",
        "    \"ckpt-dir\": valid_ckpt_dir,\n",
        "    \"vae-dir\": valid_vae_dir,\n",
        "    \"hypernetwork-dir\": valid_hypernetwork_dir,\n",
        "    \"embeddings-dir\": valid_embedding_dir,\n",
        "    \"lora-dir\": valid_lora_dir,\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python launch.py {args} {additional_arguments}\"\n",
        "\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Generated Images** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#download-generated-images)</small></small>\n",
        "# @markdown Download file manually from files tab or save to Google Drive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import drive\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(drive_dir)\n",
        "\n",
        "use_drive = True  # @param {type:\"boolean\"}\n",
        "folder_name = \"cagliostro-colab-ui\"  # @param {type: \"string\"}\n",
        "filename = \"waifu.zip\"  # @param {type: \"string\"}\n",
        "save_as = filename\n",
        "\n",
        "if os.path.exists(filename):\n",
        "    i = 1\n",
        "    while os.path.exists(f\"waifu({i}).zip\"):\n",
        "        i += 1\n",
        "    filename = f\"waifu({i}).zip\"\n",
        "\n",
        "!zip -r /content/outputs.zip .\n",
        "\n",
        "if use_drive:\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "\n",
        "    def create_folder(folder_name):\n",
        "        file_list = drive.ListFile(\n",
        "            {\n",
        "                \"q\": \"title='{}' and mimeType='application/vnd.google-apps.folder' and trashed=false\".format(\n",
        "                    folder_name\n",
        "                )\n",
        "            }\n",
        "        ).GetList()\n",
        "        if len(file_list) > 0:\n",
        "            print(\"Debug: Folder exists\")\n",
        "            folder_id = file_list[0][\"id\"]\n",
        "        else:\n",
        "            print(\"Debug: Creating folder\")\n",
        "            file = drive.CreateFile(\n",
        "                {\"title\": folder_name, \"mimeType\": \"application/vnd.google-apps.folder\"}\n",
        "            )\n",
        "            file.Upload()\n",
        "            folder_id = file.attr[\"metadata\"][\"id\"]\n",
        "        return folder_id\n",
        "\n",
        "    def upload_file(file_name, folder_id, save_as):\n",
        "        file_list = drive.ListFile(\n",
        "            {\"q\": \"title='{}' and trashed=false\".format(save_as)}\n",
        "        ).GetList()\n",
        "        if len(file_list) > 0:\n",
        "            print(\"Debug: File already exists\")\n",
        "            i = 1\n",
        "            while True:\n",
        "                new_name = (\n",
        "                    os.path.splitext(save_as)[0]\n",
        "                    + f\"({i})\"\n",
        "                    + os.path.splitext(save_as)[1]\n",
        "                )\n",
        "                file_list = drive.ListFile(\n",
        "                    {\"q\": \"title='{}' and trashed=false\".format(new_name)}\n",
        "                ).GetList()\n",
        "                if len(file_list) == 0:\n",
        "                    save_as = new_name\n",
        "                    break\n",
        "                i += 1\n",
        "        file = drive.CreateFile({\"title\": save_as, \"parents\": [{\"id\": folder_id}]})\n",
        "        file.SetContentFile(file_name)\n",
        "        file.Upload()\n",
        "        file.InsertPermission({\"type\": \"anyone\", \"value\": \"anyone\", \"role\": \"reader\"})\n",
        "        return file.attr[\"metadata\"][\"id\"]\n",
        "\n",
        "    file_id = upload_file(\"/content/outputs.zip\", create_folder(folder_name), save_as)\n",
        "    print(\n",
        "        \"Your sharing link: https://drive.google.com/file/d/\"\n",
        "        + file_id\n",
        "        + \"/view?usp=sharing\"\n",
        "    )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ojb4nAieATxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extras"
      ],
      "metadata": {
        "id": "4SUHPtGLz2m4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Generated Images V2** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#download-generated-images-v2)</small></small>\n",
        "from IPython.utils import capture\n",
        "from huggingface_hub import login\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# @markdown Download your output by upload it to **Huggingface** instead of Google Drive.\n",
        "# @markdown > Get **your** huggingface `WRITE` token [here](https://huggingface.co/settings/tokens)\n",
        "write_token = \"\"  # @param {type:\"string\"}\n",
        "# @markdown Specify where is your repo located, it will automatically create your repo if you didn't have one.\n",
        "repo_name = \"cagliostro-colab-ui\"  # @param{type:\"string\"}\n",
        "repo_name = repo_name.replace(\" \", \"-\")\n",
        "private_repo = False  # @param{type:\"boolean\"}\n",
        "# @markdown This will be compressed to zip and uploaded to datasets repo\n",
        "project_name = \"waifu\"  # @param {type :\"string\"}\n",
        "project_name = project_name.replace(\" \", \"_\")\n",
        "\n",
        "if not project_name:\n",
        "    project_name = \"waifu\"\n",
        "\n",
        "dataset_zip = project_name + \".zip\"\n",
        "output_path = os.path.join(root_dir, dataset_zip)\n",
        "commit_message = \"Feat: Upload \" + dataset_zip + \" with Cagliostro Colab UI\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    login(write_token, add_to_git_credential=True)\n",
        "output = cap.stdout.strip()\n",
        "if \"Token is valid.\" in output:\n",
        "    print(\"\u001b[1;32mLogin Succesful.\")\n",
        "\n",
        "api = HfApi()\n",
        "user = api.whoami(write_token)\n",
        "\n",
        "datasets_repo = user[\"name\"] + \"/\" + repo_name.strip()\n",
        "\n",
        "if repo_name:\n",
        "    try:\n",
        "        validate_repo_id(datasets_repo)\n",
        "        api.create_repo(\n",
        "            repo_id=datasets_repo, repo_type=\"dataset\", private=private_repo\n",
        "        )\n",
        "        print(\n",
        "            f\"\u001b[1;32mRepo created, located at https://huggingface.co/datasets/{datasets_repo}\"\n",
        "        )\n",
        "\n",
        "    except HfHubHTTPError as e:\n",
        "        print(f\"\u001b[1;32mRepo exist, skipping...\")\n",
        "\n",
        "os.chdir(drive_dir)\n",
        "print(f\"\u001b[1;32mCompressing to ZIP...\")\n",
        "with capture.capture_output() as cap:\n",
        "    !zip -rv {output_path} .\n",
        "\n",
        "print(f\"\u001b[1;32mUploading generated images... Please wait...\")\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=output_path,\n",
        "    path_in_repo=dataset_zip,\n",
        "    repo_id=datasets_repo,\n",
        "    repo_type=\"dataset\",\n",
        "    commit_message=commit_message,\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"\u001b[1;32mUpload success, download directly at https://huggingface.co/datasets/{datasets_repo}/resolve/main/{dataset_zip}\"\n",
        ")\n",
        "\n",
        "os.remove(output_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EGXqJLXwnJQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
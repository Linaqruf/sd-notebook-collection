{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/sd-notebook-collection/blob/dev/beta_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![visitor][visitor-badge]][visitor-stats] \n",
        "[![ko-fi][ko-fi-badge]][ko-fi-link]\n",
        "\n",
        "# **Cagliostro Colab UI**\n",
        "All-in-One, Customizable and Flexible Stable Diffusion for Google Colab.\n",
        "\n",
        "V3 | [Github][link-to-github] | [What's New?][README] | [Pocketbook Guide][MANUAL]\n",
        "\n",
        "<!-- [visitor-badge]: https://visitor-badge.glitch.me/badge?page_id=linaqruf.cag-webui -->\n",
        "[visitor-badge]: https://api.visitorbadge.io/api/visitors?path=Cagliostro%20Colab%20UI&label=Visitors&labelColor=%2334495E&countColor=%231ABC9C&style=flat&labelStyle=none\n",
        "[visitor-stats]: https://visitorbadge.io/status?path=Cagliostro%20Colab%20UI\n",
        "[ko-fi-badge]: https://img.shields.io/badge/Support%20me%20on%20Ko--fi-F16061?logo=ko-fi&logoColor=white&style=flat\n",
        "[ko-fi-link]: https://ko-fi.com/linaqruf\n",
        "[link-to-github]: https://github.com/Linaqruf/sd-notebook-collection/blob/main/cagliostro-colab-ui.ipynb\n",
        "[README]: https://github.com/Linaqruf/sd-notebook-collection/blob/main/README.md#whats-new\n",
        "[MANUAL]: https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#cagliostro-colab-ui-user-manual\n",
        "\n"
      ],
      "metadata": {
        "id": "WgQr3s96015a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Install Cagliostro Colab UI**\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import base64\n",
        "import shutil\n",
        "import subprocess\n",
        "from google.colab.output import eval_js\n",
        "from IPython.utils import capture\n",
        "from tqdm import tqdm\n",
        "subprocess.run(['pip', 'install', '--upgrade', 'git+https://github.com/Linaqruf/colablib'])\n",
        "from colablib.colored_print import cprint, print_line\n",
        "from colablib.utils import py_utils, config_utils, package_utils\n",
        "from colablib.utils.ubuntu_utils import ubuntu_deps\n",
        "from colablib.sd_models.downloader import aria2_download\n",
        "from colablib.utils.git_utils import update_repo, batch_update, validate_repo, reset_repo\n",
        "\n",
        "%store -r\n",
        "\n",
        "################################\n",
        "# COLAB ARGUMENTS GOES HERE\n",
        "################################\n",
        "\n",
        "# @markdown ### **Drive Config**\n",
        "mount_drive         = False  # @param {type:'boolean'}\n",
        "output_drive_folder = \"cagliostro-colab-ui/outputs\" #@param {type:'string'}\n",
        "# @markdown ### **Repo Config**\n",
        "repo_type           = \"Anapnoe\" #@param [\"AUTOMATIC1111\", \"AUTOMATIC1111-Dev\", \"Anapnoe\"]\n",
        "update_webui        = True  # @param {type:'boolean'}\n",
        "update_extensions   = True  # @param {type:'boolean'}\n",
        "commit_hash         = \"\"  # @param {type:'string'}\n",
        "dpm_v2_patch        = False  # @param {type:'boolean'}\n",
        "# @markdown > It's not recommended to set params below to `True` if you have **Colab Pro** subscription.\n",
        "ram_alloc_patch     = True  # @param {type:'boolean'}\n",
        "colab_optimizations = True  # @param {type:'boolean'}\n",
        "\n",
        "\n",
        "################################\n",
        "# DIRECTORY CONFIG\n",
        "################################\n",
        "\n",
        "# VAR\n",
        "voldemort           = base64.b64decode(\"c3RhYmxlLWRpZmZ1c2lvbi13ZWJ1aQ==\".encode('ascii')).decode('ascii')\n",
        "voldy               = base64.b64decode(\"c2Qtd2VidWk=\".encode('ascii')).decode('ascii')\n",
        "\n",
        "# ROOT DIR\n",
        "root_dir            = \"/content\"\n",
        "drive_dir           = os.path.join(root_dir, \"drive\", \"MyDrive\")\n",
        "repo_dir            = os.path.join(root_dir, \"cagliostro-colab-ui\")\n",
        "tmp_dir             = os.path.join(root_dir, \"tmp\")\n",
        "patches_dir         = os.path.join(root_dir, \"patches\")\n",
        "deps_dir            = os.path.join(root_dir, \"deps\")\n",
        "fused_dir           = os.path.join(root_dir, \"fused\")\n",
        "\n",
        "# REPO DIR\n",
        "models_dir          = os.path.join(repo_dir, \"models\", \"Stable-diffusion\")\n",
        "vaes_dir            = os.path.join(repo_dir, \"models\", \"VAE\")\n",
        "hypernetworks_dir   = os.path.join(repo_dir, \"models\", \"hypernetworks\")\n",
        "lora_dir            = os.path.join(repo_dir, \"models\", \"Lora\")\n",
        "control_dir         = os.path.join(repo_dir, \"models\", \"ControlNet\")\n",
        "esrgan_dir          = os.path.join(repo_dir, \"models\", \"ESRGAN\")\n",
        "embeddings_dir      = os.path.join(repo_dir, \"embeddings\")\n",
        "extensions_dir      = os.path.join(repo_dir, \"extensions\")\n",
        "annotator_dir       = os.path.join(extensions_dir, f\"{voldy}-controlnet\", \"annotator\")\n",
        "output_subdir       = [\"txt2img-images\", \"img2img-images\", \"extras-images\", \"txt2img-grids\", \"img2img-grids\"]\n",
        "\n",
        "# CONFIG \n",
        "config_file         = os.path.join(repo_dir, \"config.json\")\n",
        "ui_config_file      = os.path.join(repo_dir, \"ui-config.json\")\n",
        "style_path          = os.path.join(repo_dir, \"style.css\")\n",
        "download_list       = os.path.join(root_dir, \"download_list.txt\")\n",
        "\n",
        "\n",
        "################################\n",
        "# REPO TYPE CONFIG\n",
        "################################\n",
        "\n",
        "package_url = [\n",
        "    f\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/{repo_type.lower()}-webui.tar.lz4\",\n",
        "    f\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/{repo_type.lower()}-webui-deps.tar.lz4\",\n",
        "    f\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/{repo_type.lower()}-webui-cache.tar.lz4\",\n",
        "]\n",
        "\n",
        "repo_type_to_repo_name = {\n",
        "    \"anapnoe\"           : f\"anapnoe/{voldemort}-ux\",\n",
        "    \"automatic1111\"     : f\"AUTOMATIC1111/{voldemort}\",\n",
        "    \"automatic1111-dev\" : f\"AUTOMATIC1111/{voldemort}\",\n",
        "}\n",
        "\n",
        "branch_type_to_branch = {\n",
        "    \"automatic1111\"     : \"master\",\n",
        "    \"automatic1111-dev\" : \"dev\"\n",
        "}\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    for dir in  [\"root_dir\", \"fused_dir\", \"repo_dir\", \"tmp_dir\", \"models_dir\", \"vaes_dir\", \"hypernetworks_dir\", \"embeddings_dir\", \"extensions_dir\", \"lora_dir\", \"control_dir\", \"esrgan_dir\"]:\n",
        "        %store {dir}\n",
        "    for file in [\"config_file\", \"ui_config_file\", \"style_path\", \"download_list\"]:\n",
        "        %store {file}\n",
        "    for var in  [\"voldemort\", \"voldy\"]:\n",
        "        %store {var}\n",
        "    del cap\n",
        "\n",
        "def mount_func(directory):\n",
        "    output_dir = os.path.join(repo_dir, \"outputs\")\n",
        "\n",
        "    if mount_drive:\n",
        "        if not os.path.exists(directory):\n",
        "            cprint(\"Mounting google drive...\", color=\"green\", reset=False)\n",
        "            drive.mount(os.path.dirname(directory))\n",
        "        output_dir  = os.path.join(directory, output_drive_folder)\n",
        "        cprint(\"Set default output path to:\", output_dir, color=\"green\")\n",
        "        cprint()\n",
        "\n",
        "    return output_dir\n",
        "\n",
        "def setup_directories():\n",
        "    for dir in [fused_dir, models_dir, vaes_dir, \n",
        "                hypernetworks_dir, embeddings_dir, extensions_dir, \n",
        "                lora_dir, control_dir, esrgan_dir]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "def pre_download(dir, urls, desc, overwrite=False):\n",
        "    gpu_info          = py_utils.get_gpu_info()\n",
        "    version           = py_utils.get_python_version().split()[0]\n",
        "    major_minor       = \".\".join(version.split(\".\")[:2])\n",
        "    xformers_version  = \"0.0.20\"\n",
        "    python_path       = f\"/usr/local/lib/python{major_minor}/dist-packages/\"\n",
        "    ffmpy_path        = os.path.join(python_path, \"ffmpy-0.3.0.dist-info\")\n",
        "\n",
        "    for url in tqdm(urls, desc=desc):\n",
        "        filename  = py_utils.get_filename(url)\n",
        "        aria2_download(dir, filename, url, quiet=True)\n",
        "        if filename == f\"{repo_type.lower()}-webui-deps.tar.lz4\":\n",
        "            package_utils.extract_package(filename, python_path, overwrite=True)\n",
        "        else:\n",
        "            package_utils.extract_package(filename, \"/\", overwrite=overwrite)\n",
        "        os.remove(filename)\n",
        "\n",
        "    if os.path.exists(ffmpy_path):\n",
        "        shutil.rmtree(ffmpy_path)\n",
        "\n",
        "    if not 'T4' in gpu_info:\n",
        "        subprocess.run(['pip', 'uninstall', '-y', 'xformers'], check=True)\n",
        "        subprocess.run(['pip', 'install', '-q', f'xformers=={xformers_version}'], check=True)\n",
        "\n",
        "def install_dependencies():\n",
        "    ubuntu_deps_url = \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/ubuntu-deps.zip\"\n",
        "    ram_patch_url   = \"https://huggingface.co/Linaqruf/fast-repo/resolve/main/ram_patch.zip\"\n",
        "\n",
        "    ubuntu_deps(ubuntu_deps_url, deps_dir, cprint(\"Installing ubuntu dependencies\", color=\"green\", tqdm_desc=True))\n",
        "\n",
        "    if ram_alloc_patch:\n",
        "        subprocess.run([\"apt\", \"install\",  'libunwind8-dev', \"-y\"], check=True)\n",
        "        ubuntu_deps(ram_patch_url, deps_dir, cprint(\"Installing RAM allocation patch\", color=\"green\", tqdm_desc=True))\n",
        "        os.environ[\"LD_PRELOAD\"] = \"libtcmalloc.so\"\n",
        "\n",
        "def install_webui(repo_dir, desc):\n",
        "    try:\n",
        "        if not os.path.exists(repo_dir):\n",
        "            pre_download(root_dir, package_url, desc, overwrite=False)\n",
        "            return\n",
        "        \n",
        "        repo_name, _, current_branch = validate_repo(repo_dir)\n",
        "        repo_type_lower = repo_type.lower()\n",
        "        expected_repo_name = repo_type_to_repo_name.get(repo_type_lower)\n",
        "        \n",
        "        if expected_repo_name == repo_name:\n",
        "            expected_branch = branch_type_to_branch.get(repo_type_lower)\n",
        "            if expected_branch is None or expected_branch == current_branch:\n",
        "                cprint(f\"'{repo_name}' {current_branch if expected_branch else ''} already installed, skipping...\", color=\"green\")\n",
        "                return\n",
        "\n",
        "        cprint(f\"Another repository exist. Uninstall '{repo_name}'...\", color=\"green\")\n",
        "        shutil.rmtree(repo_dir)  \n",
        "        pre_download(root_dir, package_url, desc)\n",
        "    except Exception as e:\n",
        "        cprint(f\"An error occurred: {e}\", color=\"green\")\n",
        "\n",
        "def configure_output_path(config_path, output_dir, output_subdir):\n",
        "    config = config_utils.read_config(config_path)\n",
        "    config_updates = {\n",
        "        \"outdir_txt2img_samples\"  : os.path.join(output_dir, output_subdir[0]),\n",
        "        \"outdir_img2img_samples\"  : os.path.join(output_dir, output_subdir[1]),\n",
        "        \"outdir_extras_samples\"   : os.path.join(output_dir, output_subdir[2]),\n",
        "        \"outdir_txt2img_grids\"    : os.path.join(output_dir, output_subdir[3]),\n",
        "        \"outdir_img2img_grids\"    : os.path.join(output_dir, output_subdir[4])\n",
        "    }\n",
        "\n",
        "    config.update(config_updates)\n",
        "    config_utils.write_config(config_path, config)\n",
        "\n",
        "    for dir in output_subdir:\n",
        "        os.makedirs(os.path.join(output_dir, dir), exist_ok=True)\n",
        "\n",
        "def prepare_environment():\n",
        "    cprint(f\"Preparing environment...\", color=\"green\")\n",
        "\n",
        "    os.environ[\"colab_url\"]               = eval_js(\"google.colab.kernel.proxyPort(7860, {'cache': false})\")\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]    = \"3\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"]    = \"1\"\n",
        "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = \"garbage_collection_threshold:0.9,max_split_size_mb:512\"\n",
        "    os.environ[\"PYTHONWARNINGS\"]          = \"ignore\"\n",
        "\n",
        "def main():\n",
        "    global output_dir\n",
        "\n",
        "    os.chdir(root_dir)\n",
        "    start_time = time.time()\n",
        "    \n",
        "    output_dir = mount_func(drive_dir)\n",
        "\n",
        "    gpu_info    = py_utils.get_gpu_info(get_gpu_name=True)\n",
        "    python_info = py_utils.get_python_version()\n",
        "    torch_info  = py_utils.get_torch_version()\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\" [-] Current GPU:\", gpu_info, color=\"flat_yellow\")\n",
        "    cprint(f\" [-] Python\", python_info, color=\"flat_yellow\")\n",
        "    cprint(f\" [-] Torch\", torch_info, color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    install_dependencies()\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    install_webui(repo_dir, cprint(f\"Unpacking {repo_type} Webui\", color=\"green\", tqdm_desc=True))\n",
        "    prepare_environment()\n",
        "    setup_directories ()\n",
        "    configure_output_path(config_file, output_dir, output_subdir)\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    if update_webui and not commit_hash:\n",
        "        update_repo(cwd=repo_dir, args=\"-X theirs --rebase --autostash\")\n",
        "\n",
        "    if commit_hash:\n",
        "        reset_repo(repo_dir, commit_hash)\n",
        "\n",
        "    repo_name, current_commit_hash, current_branch = validate_repo(repo_dir)\n",
        "    cprint(f\"Using '{repo_name}' repository...\", color=\"green\")\n",
        "    cprint(f\"Branch: {current_branch}, Commit hash: {current_commit_hash}\", color=\"green\")\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    if dpm_v2_patch:\n",
        "        os.makedirs(patches_dir)\n",
        "        dpm_v2_url  = \"https://gist.github.com/neggles/75eaacb3f49c209636be61fa96ca95ca/raw/f8c6382f0af65038149fd4258f8462697b698073/01-add-DPMPP-2M-V2.patch\"\n",
        "        dpm_v2_file = os.path.join(patches_dir, '01-add-DPMPP-2M-V2.patch')\n",
        "        subprocess.run(['wget', dpm_v2_url, '-P', patches_dir, '-c'])\n",
        "        subprocess.run(['git', 'apply', '--whitespace=fix', dpm_v2_file], cwd=repo_dir)\n",
        "        shutil.rmtree(patches_dir)\n",
        "\n",
        "    if colab_optimizations:\n",
        "        subprocess.run([\"sed\", \"-i\", f\"s@os.path.splitext(checkpoint_file)@os.path.splitext(checkpoint_file); map_location='cuda'@\", os.path.join(repo_dir, \"modules\", \"sd_models.py\")])\n",
        "        subprocess.run([\"sed\", \"-i\", f\"s@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@\", os.path.join(repo_dir, \"webui.py\")])\n",
        "        subprocess.run([\"sed\", \"-i\", f\"s@map_location='cpu'@map_location='cuda'@\", os.path.join(repo_dir, \"modules\", \"extras.py\")])\n",
        "\n",
        "    if update_extensions:\n",
        "        batch_update(fetch=True, directory=extensions_dir, desc=cprint(f\"Updating extensions\", color=\"green\", tqdm_desc=True))\n",
        "\n",
        "    if not os.path.exists(download_list):\n",
        "        download_list_url = \"https://raw.githubusercontent.com/Linaqruf/sd-notebook-collection/main/config/download_list.txt\"\n",
        "        aria2_download(os.path.dirname(download_list), os.path.basename(download_list), download_list_url, quiet=True)\n",
        "\n",
        "    elapsed_time = py_utils.calculate_elapsed_time(start_time)\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Finished installation. Took {elapsed_time}.\", color=\"flat_yellow\")\n",
        "    cprint(\"All is done! Go to the next step.\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "A6c7-qjDdb0X",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Model and VAE**\n",
        "import os\n",
        "import time\n",
        "from colablib.utils import py_utils\n",
        "from colablib.colored_print import cprint, print_line\n",
        "from colablib.sd_models.downloader import aria2_download, get_modelname\n",
        "\n",
        "%store -r\n",
        "\n",
        "################################\n",
        "# COLAB ARGUMENTS GOES HERE\n",
        "################################\n",
        "\n",
        "# @markdown ### **Stable Diffusion v1.x Model**\n",
        "Anything_V3_0         = False  # @param {type: 'boolean'}\n",
        "AnyLoRA_Default       = False  # @param {type: 'boolean'}\n",
        "AnyLoRA_Anime_Mix     = True  # @param {type: 'boolean'}\n",
        "Ghost_Note_Delta      = False  # @param {type: 'boolean'}\n",
        "SDHK_V3               = False  # @param {type: 'boolean'}\n",
        "Majic_Mix_V5          = False  # @param {type: 'boolean'}\n",
        "# @markdown ### **Stable Diffusion v2.x Model**\n",
        "Replicant_V3          = False  # @param {type: 'boolean'}\n",
        "Illuminati_Diffusion  = False  # @param {type: 'boolean'}\n",
        "# @markdown ### **VAE Model**\n",
        "Anime                 = True  # @param {type: 'boolean'}\n",
        "Blessed               = False  # @param {type: 'boolean'}\n",
        "Waifu_Diffusion       = False  # @param {type: 'boolean'}\n",
        "Stable_Diffusion      = False  # @param {type: 'boolean'}\n",
        "\n",
        "# VAR\n",
        "read_token  = \"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\"\n",
        "user_header = f\"Authorization: Bearer {read_token}\"\n",
        "\n",
        "################################\n",
        "# URL DICT GOES HERE\n",
        "################################\n",
        "\n",
        "model_dict = {\n",
        "    \"Anything_V3_0\"         : \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/anything-v3-0-pruned.ckpt\",\n",
        "    \"AnyLoRA_Default\"       : \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/AnyLoRA_noVae_fp16-pruned.safetensors\",\n",
        "    \"AnyLoRA_Anime_Mix\"     : \"https://huggingface.co/Linaqruf/stolen/resolve/main/fp16/aamAnyloraAnimeMixAnime_v10-fp16-pruned.safetensors\",\n",
        "    \"Ghost_Note_Delta\"      : \"https://huggingface.co/Linaqruf/stolen/resolve/main/fp16/GhostNoteDelta_m0528_fp16.safetensors\",\n",
        "    \"SDHK_V3\"               : \"https://huggingface.co/Linaqruf/stolen/resolve/main/fp16/sdhk_v30.safetensors\",\n",
        "    \"Majic_Mix_V5\"          : \"https://huggingface.co/Linaqruf/stolen/resolve/main/fp16/majicmixRealistic_v5.safetensors\",\n",
        "    \"Replicant_V3\"          : \"https://huggingface.co/gsdf/Replicant-V3.0/resolve/main/Replicant-V3.0_fp16.safetensors\",\n",
        "    \"Illuminati_Diffusion\"  : \"https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/illuminatiDiffusionV1_v11.safetensors\",\n",
        "}\n",
        "\n",
        "vae_dict = {\n",
        "    \"Anime\"                 : \"https://huggingface.co/NoCrypt/resources/resolve/main/any.vae.safetensors\",\n",
        "    \"Blessed\"               : \"https://huggingface.co/NoCrypt/resources/resolve/main/blessed2.vae.safetensors\",\n",
        "    \"Waifu_Diffusion\"       : \"https://huggingface.co/NoCrypt/resources/resolve/main/wd.vae.safetensors\",\n",
        "    \"Stable_Diffusion\"      : \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors\",    \n",
        "}\n",
        "\n",
        "def filter_dict_items(dict_items):\n",
        "    result_list = []\n",
        "    for key, url in dict_items.items():\n",
        "        if globals().get(key):\n",
        "            result_list.append((key, url))\n",
        "    return result_list\n",
        "\n",
        "def main():\n",
        "    start_time = time.time()\n",
        "    \n",
        "    download_list = [\n",
        "        (filter_dict_items(model_dict), models_dir),\n",
        "        (filter_dict_items(vae_dict), vaes_dir)\n",
        "    ]\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(\" [-] Downloading Stable Diffusion Models and VAEs...\", color=\"flat_yellow\")\n",
        "    for lst, dst in download_list:\n",
        "        for key, url in lst:\n",
        "            print_line(80, color=\"green\")\n",
        "            extensions = os.path.splitext(get_modelname(url))[1]\n",
        "            if dst == vaes_dir:\n",
        "                extensions = \".vae\" + extensions\n",
        "            aria2_download(url=url, download_dir=dst, filename=key + extensions, user_header=user_header)\n",
        "\n",
        "    elapsed_time = py_utils.calculate_elapsed_time(start_time)\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Download finished. Took {elapsed_time}.\", color=\"flat_yellow\")\n",
        "    cprint(\"All is done! Go to the next step.\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "7nUM-wRFhBa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **ControlNet v1.1** \n",
        "import time\n",
        "import shutil\n",
        "import os\n",
        "import subprocess\n",
        "from tqdm import tqdm\n",
        "from colablib.sd_models.downloader import aria2_download\n",
        "from colablib.utils import config_utils, py_utils, git_utils\n",
        "from colablib.colored_print import cprint, print_line\n",
        "from colablib.utils.py_utils import get_filename\n",
        "\n",
        "%store -r \n",
        "\n",
        "# @markdown ### **ControlNet Annotator**\n",
        "pre_download_annotator      = True   # @param {type: 'boolean'}\n",
        "# @markdown ### **SDv1.x ControlNet Model**\n",
        "control_v11_sd15_model      = True   # @param {type: 'boolean'}\n",
        "t2i_adapter_model           = False  # @param {type: 'boolean'}\n",
        "# @markdown ### **SDv2.x ControlNet Model**\n",
        "control_v11_sd21_model      = False  # @param {type: 'boolean'}\n",
        "# @markdown ### **ControlNet Config**\n",
        "control_net_max_models_num  = 2      # @param {type:\"slider\", min:1, max:10, step:1}\n",
        "\n",
        "annotator_dict = {\n",
        "    \"midas\"         : \"https://huggingface.co/lllyasviel/ControlNet/resolve/main/annotator/ckpts/dpt_hybrid-midas-501f0c75.pt\",\n",
        "    \"leres\"         : [\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/res101.pth\",\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/latest_net_G.pth\"\n",
        "    ],\n",
        "    \"hed\"           : \"https://huggingface.co/lllyasviel/Annotators/resolve/main/ControlNetHED.pth\",\n",
        "    \"mlsd\"          : \"https://huggingface.co/lllyasviel/ControlNet/resolve/main/annotator/ckpts/mlsd_large_512_fp32.pth\",\n",
        "    \"openpose\"      : [\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/body_pose_model.pth\",\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/hand_pose_model.pth\",\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/facenet.pth\"\n",
        "    ],\n",
        "    \"clip_vision\"   : \"https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin\",\n",
        "    \"pidinet\"       : \"https://huggingface.co/lllyasviel/Annotators/resolve/main/table5_pidinet.pth\",\n",
        "    \"uniformer\"     : \"https://huggingface.co/lllyasviel/ControlNet/resolve/main/annotator/ckpts/upernet_global_small.pth\",\n",
        "    \"zoedepth\"      : \"https://huggingface.co/lllyasviel/Annotators/resolve/main/ZoeD_M12_N.pt\",\n",
        "    \"normal_bae\"    : \"https://huggingface.co/lllyasviel/Annotators/resolve/main/scannet.pt\",\n",
        "    \"oneformer\"     : [\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/150_16_swin_l_oneformer_coco_100ep.pth\",\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/250_16_swin_l_oneformer_ade20k_160k.pth\"\n",
        "    ],\n",
        "    \"lineart\"       : [\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/sk_model.pth\",\n",
        "        \"https://huggingface.co/lllyasviel/Annotators/resolve/main/sk_model2.pth\"\n",
        "    ],\n",
        "    \"lineart_anime\" : \"https://huggingface.co/lllyasviel/Annotators/resolve/main/netG.pth\",\n",
        "    \"manga_line\"    : \"https://huggingface.co/lllyasviel/Annotators/resolve/main/erika.pth\"\n",
        "}\n",
        "\n",
        "control_v11_sd15_url = [\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_scribble_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_seg_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors\",\n",
        "    \"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile_fp16.safetensors\",\n",
        "]\n",
        "\n",
        "control_v11_sd21_url = [\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_ade20k.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_canny.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_color.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_depth.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_hed.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_lineart.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_normalbae.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_openpose.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_openposev2.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_scribble.safetensors\",\n",
        "    \"https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_zoedepth.safetensors\"\n",
        "]\n",
        "\n",
        "t2i_adapter_url = [\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd15v2.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd15v2.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd15v2.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth\",\n",
        "    \"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_zoedepth_sd15v1.pth\"\n",
        "]\n",
        "\n",
        "def cldm_config_path(destination_path):\n",
        "    if \"control\" in destination_path:\n",
        "        if \"sd15\" in destination_path:\n",
        "            return \"control_v11e_sd15_shuffle.yaml\" if \"_shuffle_\" in destination_path else \"cldm_v15.yaml\"\n",
        "        if \"sd21\" in destination_path:\n",
        "            return \"cldm_v21.yaml\"\n",
        "    elif \"t2i\" in destination_path:\n",
        "        adapter_name = os.path.splitext(os.path.basename(destination_path))[0]\n",
        "        return adapter_name + \".yaml\"\n",
        "    return None\n",
        "\n",
        "def cldm_config(destination_path):\n",
        "    repo_name, _, _ = git_utils.validate_repo(repo_dir)\n",
        "\n",
        "    control_net_model_config = cldm_config_path(destination_path)\n",
        "    if control_net_model_config is not None:\n",
        "        cldm_config_src = os.path.join(extensions_dir, os.path.join(f\"{voldy}-controlnet\", \"models\", control_net_model_config))\n",
        "        cldm_config_dst = os.path.splitext(destination_path)[0] + \".yaml\"\n",
        "        if not os.path.exists(cldm_config_dst):\n",
        "            shutil.copy(cldm_config_src, cldm_config_dst)\n",
        "\n",
        "def batch_download(urls, dst, desc=None, quiet=False, cldm_model=False):\n",
        "    for url in tqdm(urls, disable=quiet, desc=cprint(desc, color=\"green\", tqdm_desc=True)):\n",
        "        filename = get_filename(url)\n",
        "        aria2_download(url=url, download_dir=dst, filename=filename, quiet=True)\n",
        "        if cldm_model:\n",
        "            cldm_config(os.path.join(dst, filename))\n",
        "\n",
        "def download_annotator(directory, desc):\n",
        "    for category, urls in tqdm(annotator_dict.items(), desc=cprint(desc, color=\"green\", tqdm_desc=True)):\n",
        "        if category == \"clip_vision\":\n",
        "            dst = os.path.join(directory, \"clip_vision\")\n",
        "        else:\n",
        "            dst = os.path.join(directory, \"downloads\", category)\n",
        "        os.makedirs(dst, exist_ok=True)\n",
        "        urls = [urls] if isinstance(urls, str) else urls\n",
        "        batch_download(urls, dst, quiet=True)\n",
        "\n",
        "def main():\n",
        "    start_time = time.time()\n",
        "\n",
        "    repo_name, _, _ = git_utils.validate_repo(repo_dir)\n",
        "\n",
        "    config = config_utils.read_config(config_file)\n",
        "    config[\"control_net_max_models_num\"]        = control_net_max_models_num\n",
        "    config[\"control_net_models_path\"]           = control_dir\n",
        "    config[\"control_net_allow_script_control\"]  = True\n",
        "    config_utils.write_config(config_file, config)\n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(\" [-] Downloading ControlNet Models...\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    if pre_download_annotator:\n",
        "        download_annotator(annotator_dir, \"Downloading ControlNet Annotator/Preprocessor\")\n",
        "    if control_v11_sd15_model:\n",
        "        batch_download(control_v11_sd15_url, control_dir, \"Downloading SDv1.x ControlNet Model\", cldm_model=True)\n",
        "    if control_v11_sd21_model:\n",
        "        batch_download(control_v11_sd21_url, control_dir, \"Downloading SDv2.x ControlNet Model\", cldm_model=True)\n",
        "    if t2i_adapter_model:\n",
        "        batch_download(t2i_adapter_url, control_dir, \"Downloading SDv1.x Text2Image Adapter Model\", cldm_model=True)\n",
        "\n",
        "    elapsed_time = py_utils.calculate_elapsed_time(start_time)\n",
        "    cprint()\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Download finished. Took {elapsed_time}.\", color=\"flat_yellow\")\n",
        "    cprint(\"All is done! Go to the next step.\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "            \n",
        "main()"
      ],
      "metadata": {
        "id": "K28QYTFhf7Cu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Custom Download Corner**\n",
        "import os\n",
        "import time\n",
        "from pydantic import BaseModel\n",
        "from colablib.utils.py_utils import get_filename\n",
        "from colablib.sd_models.downloader import aria2_download, download\n",
        "from colablib.utils.ubuntu_utils import unionfuse\n",
        "from colablib.utils.git_utils import clone_repo\n",
        "from colablib.colored_print import cprint, print_line\n",
        "from colablib.utils.config_utils import read_config\n",
        "\n",
        "%store -r\n",
        "\n",
        "# @markdown\n",
        "# @markdown ### **Download from Custom URLs**\n",
        "# @markdown - Use comma separation for multiple URLs, e.g. `url1, url2, url3`.\n",
        "# @markdown - To load Google Drive, use `fuse:` followed by path, e.g. `fuse:/content/MyDrive/LoRA`.\n",
        "# @markdown - Copy your model path from Google Drive to URL fields to copy your model to the web UI models directory.\n",
        "custom_model_url        = \"\"  # @param {'type': 'string'}\n",
        "custom_vae_url          = \"\"  # @param {'type': 'string'}\n",
        "custom_embedding_url    = \"\"  # @param {'type': 'string'}\n",
        "custom_LoRA_url         = \"\"  # @param {'type': 'string'}\n",
        "custom_hypernetwork_url = \"\"  # @param {'type': 'string'}\n",
        "custom_extensions_url   = \"https://github.com/Zuellni/Stable-Diffusion-WebUI-Image-Filters\"  # @param {'type': 'string'}\n",
        "custom_upscaler_url     = \"https://huggingface.co/Linaqruf/stolen/resolve/main/upscaler/4x_NMKD-Superscale-SP_178000_G.pth, https://huggingface.co/Linaqruf/stolen/resolve/main/upscaler/4x_NMKD-YandereNeoXL_200k.pth\"  # @param {'type': 'string'}\n",
        "# @markdown ### <br>`NEW` **Download from Textfile**\n",
        "# @markdown - Provide a custom download URL for a `.txt` file instead of using the URL field. Edit the file: `/content/download_list.txt`. \n",
        "# @markdown - Available hashtags: `#model`, `#vae`, `#embedding`, `#lora`, `#hypernetwork`, `#extensions`, `#upscaler`.\n",
        "# @markdown - Or you can input your `.txt` file in `custom_download_list_url` below. Works for `pastebin`.\n",
        "custom_download_list_url = \"https://pastebin.com/LwcZC6b6\"  # @param {'type': 'string'}\n",
        "\n",
        "class CustomDirs(BaseModel):\n",
        "    url: str\n",
        "    dst: str\n",
        "\n",
        "custom_dirs = {\n",
        "    \"model\"       : CustomDirs(url=custom_model_url, dst=models_dir),\n",
        "    \"vae\"         : CustomDirs(url=custom_vae_url, dst=vaes_dir),\n",
        "    \"embedding\"   : CustomDirs(url=custom_embedding_url, dst=embeddings_dir),\n",
        "    \"lora\"        : CustomDirs(url=custom_LoRA_url, dst=lora_dir),\n",
        "    \"hypernetwork\": CustomDirs(url=custom_hypernetwork_url, dst=hypernetworks_dir),\n",
        "    \"extensions\"  : CustomDirs(url=custom_extensions_url, dst=extensions_dir),\n",
        "    \"upscaler\"    : CustomDirs(url=custom_upscaler_url, dst=esrgan_dir)\n",
        "}\n",
        "\n",
        "def fuse(url, key, dst):\n",
        "    if \"extensions\" in key:\n",
        "        cprint(f\"Folder can't be fused, skipping...\")\n",
        "        return\n",
        "\n",
        "    path = url.split(\"fuse:\")[1].strip()\n",
        "    category_dir = os.path.join(fused_dir, key)\n",
        "    if os.path.exists(category_dir):\n",
        "        cprint(f\"Folder '{category_dir}' is already fused, skipping...\", color=\"yellow\")\n",
        "        return\n",
        "\n",
        "    cprint(f\"Fusing process started for PATH: '{path}'\", color=\"green\")\n",
        "    unionfuse(category_dir, path, dst)\n",
        "    cprint(f\"Fusing process completed. Valid '{key}' folder located at: '{category_dir}' \", color=\"green\") \n",
        "\n",
        "def parse_urls(filename):\n",
        "    content = read_config(filename)\n",
        "    lines   = content.strip().split('\\n')\n",
        "    result  = {}\n",
        "    key     = ''\n",
        "    for line in lines:\n",
        "        if not line.strip():\n",
        "            continue\n",
        "        if line.startswith('//'):\n",
        "            continue\n",
        "        if line.startswith('#'):\n",
        "            key = line[1:].lower()\n",
        "            result[key] = []\n",
        "        else:\n",
        "            urls = [url.strip() for url in line.split(',') if url.strip() != '']\n",
        "            result[key].extend(urls)\n",
        "    return result\n",
        "\n",
        "def custom_download(custom_dirs):\n",
        "    for key, value in custom_dirs.items():\n",
        "        urls     = value.url.split(\",\")  # Split the comma-separated URLs\n",
        "        dst      = value.dst\n",
        "        \n",
        "        if value.url:\n",
        "            print_line(80, color=\"green\")\n",
        "            cprint(f\" [-] Downloading Custom {key}...\", color=\"flat_yellow\")\n",
        "            \n",
        "        for url in urls:\n",
        "            url = url.strip()  # Remove leading/trailing whitespaces from each URL\n",
        "            if url != \"\":  \n",
        "                print_line(80, color=\"green\")\n",
        "                if \"|\" in url:\n",
        "                    url, filename = map(str.strip, url.split(\"|\"))\n",
        "                else:\n",
        "                    if not url.startswith(\"fuse:\"):\n",
        "                        filename = get_filename(url)\n",
        "\n",
        "                if url.startswith(\"fuse:\"):\n",
        "                    fuse(url, key, dst)\n",
        "                elif key == \"extensions\":\n",
        "                    clone_repo(url, cwd=dst)\n",
        "                else:\n",
        "                    download(url=url, filename=filename, dst=dst, quiet=False)\n",
        "\n",
        "def download_from_textfile(filename):\n",
        "    for key, urls in parse_urls(filename).items():\n",
        "        key_lower = key.lower()\n",
        "        if key_lower in custom_dirs:\n",
        "            if custom_dirs[key_lower].url:\n",
        "                custom_dirs[key_lower].url += ',' + ','.join(urls)\n",
        "            else:\n",
        "                custom_dirs[key_lower].url = ','.join(urls)\n",
        "        else:\n",
        "            cprint(f\"Warning: Category '{key}' from the file is not found in custom_dirs.\", color=\"yellow\")\n",
        "\n",
        "def custom_download_list(url):\n",
        "    filename = \"custom_download_list.txt\"\n",
        "    filepath = os.path.join(root_dir, filename)\n",
        "    if os.path.exists(filepath):\n",
        "        os.remove(filepath)\n",
        "    if 'pastebin.com' in url:\n",
        "        if 'raw' not in url:\n",
        "            url = url.replace('pastebin.com', 'pastebin.com/raw')\n",
        "    download(url=url, filename=filename, dst=root_dir, quiet=True)\n",
        "    return filepath\n",
        "\n",
        "def main():\n",
        "    start_time    = time.time()\n",
        "    textfile_path = download_list\n",
        "    if custom_download_list_url:\n",
        "        textfile_path = custom_download_list(custom_download_list_url)\n",
        "    download_from_textfile(textfile_path)\n",
        "    custom_download(custom_dirs)\n",
        "    \n",
        "    elapsed_time  = py_utils.calculate_elapsed_time(start_time)\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Download finished. Took {elapsed_time}.\", color=\"flat_yellow\")\n",
        "    cprint(\"All is done! Go to the next step.\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SoZcrfQk6Y2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import string\n",
        "import threading\n",
        "from IPython.display import clear_output, display, HTML\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional\n",
        "from colablib.utils import config_utils\n",
        "from colablib.utils.git_utils import validate_repo\n",
        "\n",
        "%store -r\n",
        "\n",
        "################################\n",
        "# COLAB ARGUMENTS GOES HERE\n",
        "################################\n",
        "\n",
        "# @markdown ### **Alternative Tunnel**\n",
        "# @markdown > Recommended Tunnels: `ngrok` > `gradio` > `cloudflared` > `remotemoe` > `localhostrun` > `googleusercontent`\n",
        "select_tunnel         = \"gradio\" # @param ['gradio', 'multiple','cloudflared', 'localhostrun', 'remotemoe', \"googleusercontent\"]\n",
        "# @markdown > Get your `ngrok_token` [here](https://dashboard.ngrok.com/get-started/your-authtoken) \n",
        "ngrok_token           = \"\" # @param {type: 'string'}\n",
        "ngrok_region          = \"ap\" # @param [\"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "# @markdown ### **UI/UX Config**\n",
        "select_theme          = \"minimal_orange\" # @param ['moonlight', 'ogxRed', 'fun', 'ogxCyan', 'ogxCyanInvert', 'ogxBGreen', 'default_orange', 'tron2', 'd-230-52-94', 'minimal', 'ogxRedYellow', 'retrog', 'ogxRedPurple', 'ogxGreen', 'tron', 'default_cyan', 'default', 'backup', 'minimal_orange', 'Golde']\n",
        "# @markdown Set `use_preset` for using default prompt, resolution, sampler, and other settings\n",
        "use_presets           = True # @param {type: 'boolean'}\n",
        "# @markdown ### **Arguments**\n",
        "use_gradio_auth       = True # @param {type: 'boolean'}\n",
        "accelerator           = \"xformers\" # @param ['xformers', 'opt-sdp-attention', 'opt-sdp-no-mem-attention', 'opt-split-attention']\n",
        "auto_select_model     = False # @param {type: 'boolean'}\n",
        "auto_select_vae       = True # @param {type: 'boolean'}\n",
        "additional_arguments  = \"--lowram --no-half-vae --theme dark\" #@param {type: 'string'}\n",
        "\n",
        "# GRADIO AUTH\n",
        "user                  = \"cagliostro\"\n",
        "password              = \"\".join(random.choices(string.ascii_letters + string.digits, k=6))\n",
        "\n",
        "def change_theme(filename):\n",
        "    themes_folder   = os.path.join(repo_dir, \"extensions-builtin\", \"sd_theme_editor\", \"themes\")\n",
        "    themes_file     = os.path.join(themes_folder, f\"{filename}.css\")\n",
        "\n",
        "    style_config    = config_utils.read_config(style_path)\n",
        "    style_contents  = style_config.split(\"/*BREAKPOINT_CSS_CONTENT*/\")[1]\n",
        "\n",
        "    theme_config    = config_utils.read_config(themes_file)\n",
        "    style_data      = \":host{\" + theme_config + \"}\" + \"/*BREAKPOINT_CSS_CONTENT*/\" + style_contents\n",
        "    config_utils.write_config(style_path, style_data)\n",
        "\n",
        "def play_audio(url):\n",
        "    display(HTML(f'<audio src=\"{url}\" controls autoplay style=\"display:none\"></audio>'))\n",
        "\n",
        "def is_valid(valid_dir, file_types):\n",
        "    return [f for f in os.listdir(valid_dir) if f.endswith(file_types)]\n",
        "\n",
        "def auto_select_file(valid_dir, config_key, file_types):\n",
        "    valid_files = is_valid(valid_dir, file_types)\n",
        "    if valid_files:\n",
        "        file_path = random.choice(valid_files)\n",
        "        if os.path.exists(os.path.join(valid_dir, file_path)):\n",
        "            config = config_utils.read_config(config_file)\n",
        "            config[config_key] = file_path\n",
        "            config_utils.write_config(config_file, config)\n",
        "        return file_path\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def ui_preset_config():\n",
        "    global default_upscaler, default_sampler_v2\n",
        "\n",
        "    default_prompt        = \"masterpiece, best quality,\"\n",
        "    default_neg_prompt    = \"(worst quality, low quality:1.4)\"\n",
        "    default_sampler       = \"DPM++ 2M Karras\"\n",
        "    default_sampler_v2    = \"DPM++ 2M Karras v2\"\n",
        "    default_steps         = 20\n",
        "    default_width         = 512\n",
        "    default_height        = 768\n",
        "    default_strength      = 0.55\n",
        "    default_cfg_scale     = 7\n",
        "    default_upscaler       = \"Latent (nearest-exact)\"\n",
        "\n",
        "    config = {\n",
        "        \"Prompt/value\"              : default_prompt,\n",
        "        \"Negative prompt/value\"     : default_neg_prompt,\n",
        "        \"Sampling method/value\"     : default_sampler,\n",
        "        \"Sampling steps/value\"      : default_steps,\n",
        "        \"Width/value\"               : default_width,\n",
        "        \"Height/value\"              : default_height,\n",
        "        \"Denoising strength/value\"  : default_strength,\n",
        "        \"CFG Scale/value\"           : default_cfg_scale\n",
        "    }\n",
        "\n",
        "    return config\n",
        "\n",
        "def configure_main_settings(config_file: str, lora_dir: str, use_presets: bool, dpm_v2_patch: bool, ui_config_file: str):\n",
        "    config = config_utils.read_config(config_file)\n",
        "\n",
        "    config[\"additional_networks_extra_lora_path\"] = lora_dir\n",
        "    config[\"CLIP_stop_at_last_layers\"] = 2\n",
        "    config[\"eta_noise_seed_delta\"] = 0\n",
        "    config[\"show_progress_every_n_steps\"] = 10\n",
        "    config[\"show_progressbar\"] = True\n",
        "    config[\"samples_filename_pattern\"] = \"[model_name]_[seed]\"\n",
        "    config[\"state\"] = [\"tabs\"]\n",
        "    config[\"state_txt2img\"] = [\"prompt\", \"negative_prompt\", \"styles\", \"sampling\", \"sampling_steps\", \"width\", \"height\", \"batch_count\", \"batch_size\", \"hires_resize_y\", \"hires_resize_x\", \"hires_scale\", \"hires_steps\", \"hires_upscaler\", \"hires_fix\", \"tiling\", \"restore_faces\", \"cfg_scale\", \"hires_denoising_strength\"]\n",
        "    config[\"state_img2img\"] = [\"prompt\", \"negative_prompt\", \"styles\", \"sampling\", \"resize_mode\", \"sampling_steps\", \"tiling\", \"restore_faces\", \"width\", \"height\", \"batch_count\", \"batch_size\", \"cfg_scale\", \"denoising_strength\"]\n",
        "    config[\"state_extensions\"] = [\"control-net\"]\n",
        "\n",
        "    quicksettings_values = [\"sd_model_checkpoint\", \"sd_vae\", \"CLIP_stop_at_last_layers\", \n",
        "                            \"use_old_karras_scheduler_sigmas\", \"always_discard_next_to_last_sigma\"]\n",
        "\n",
        "    if \"quicksettings\" in config:\n",
        "        config[\"quicksettings\"] = \", \".join(quicksettings_values)\n",
        "    elif \"quicksettings_list\" in config:\n",
        "        config[\"quicksettings_list\"] = quicksettings_values\n",
        "\n",
        "    config_utils.write_config(config_file, config)\n",
        "\n",
        "    if use_presets:\n",
        "        if dpm_v2_patch:\n",
        "            preset_config = ui_preset_config()\n",
        "            preset_config[\"Sampling method/value\"] = default_sampler_v2\n",
        "        configure_ui_settings(ui_config_file)\n",
        "\n",
        "def configure_ui_settings(ui_config_file: str):\n",
        "    config = config_utils.read_config(ui_config_file)\n",
        "    preset_config = ui_preset_config()\n",
        "    for key in [\"txt2img\", \"img2img\"]:\n",
        "        for subkey, value in preset_config.items():\n",
        "            config[f\"{key}/{subkey}\"] = value\n",
        "\n",
        "    config[\"txt2img/Upscaler/value\"] = default_upscaler\n",
        "    config_utils.write_config(ui_config_file, config)\n",
        "\n",
        "def is_dir_exist(cloned_dir, original_dir):\n",
        "    if os.path.exists(cloned_dir):\n",
        "        return cloned_dir \n",
        "    else:\n",
        "        return original_dir\n",
        "\n",
        "def parse_args(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    return args\n",
        "\n",
        "def main():\n",
        "    global auto_select_model, auto_select_vae\n",
        "\n",
        "    audio_thread = threading.Thread(target=play_audio, args=(\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\",))\n",
        "    audio_thread.start()\n",
        "    \n",
        "    repo_name, _, _ = validate_repo(repo_dir)\n",
        "    if \"anapnoe\" in repo_name:\n",
        "        change_theme(select_theme)\n",
        "\n",
        "    valid_ckpt_dir          = is_dir_exist(os.path.join(fused_dir, \"model\"), models_dir)\n",
        "    valid_vae_dir           = is_dir_exist(os.path.join(fused_dir, \"vae\"), vaes_dir)\n",
        "    valid_embedding_dir     = is_dir_exist(os.path.join(fused_dir, \"embedding\"), embeddings_dir)\n",
        "    valid_lora_dir          = is_dir_exist(os.path.join(fused_dir, \"lora\"), lora_dir)\n",
        "    valid_hypernetwork_dir  = is_dir_exist(os.path.join(fused_dir, \"hypernetwork\"), hypernetworks_dir)\n",
        "\n",
        "    \n",
        "\n",
        "    print_line(80, color=\"green\")\n",
        "    cprint(f\"Launching '{repo_name}'\", color=\"flat_yellow\")\n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    if not is_valid(valid_ckpt_dir, ('.ckpt', '.safetensors')):\n",
        "        cprint(f\"No checkpoints were found in the directory '{valid_ckpt_dir}'.\", color=\"yellow\")\n",
        "        url = \"https://huggingface.co/Linaqruf/stolen/resolve/main/fp16/aamAnyloraAnimeMixAnime_v10-fp16-pruned.safetensors\"\n",
        "        filename = \"AnyLoRA_Anime_mix.safetensors\"\n",
        "        aria2_download(url=url, download_dir=valid_ckpt_dir, filename=filename)\n",
        "        print_line(80, color=\"green\")\n",
        "        auto_select_model = True\n",
        "\n",
        "    if not is_valid(valid_vae_dir, ('.vae.pt', '.vae.safetensors', '.pt', '.ckpt')):\n",
        "        cprint(f\"No VAEs were found in the directory '{valid_vae_dir}'.\", color=\"yellow\")\n",
        "        url = \"https://huggingface.co/NoCrypt/resources/resolve/main/any.vae.safetensors\"\n",
        "        filename = \"Anime.vae.safetensors\"\n",
        "        aria2_download(url=url, download_dir=valid_vae_dir, filename=filename) \n",
        "        print_line(80, color=\"green\")\n",
        "        auto_select_vae = True\n",
        "\n",
        "    if auto_select_model:\n",
        "        selected_model  = auto_select_file(valid_ckpt_dir, \"sd_model_checkpoint\", ('.ckpt', '.safetensors'))\n",
        "        cprint(f\"Selected Model: {selected_model}\", color=\"green\")\n",
        "\n",
        "    if auto_select_vae:\n",
        "        selected_vae    = auto_select_file(valid_vae_dir, \"sd_vae\", ('.vae.pt', '.vae.safetensors', '.pt', '.ckpt'))\n",
        "        cprint(f\"Selected VAE: {selected_vae}\", color=\"green\")\n",
        "    \n",
        "    print_line(80, color=\"green\")\n",
        "\n",
        "    configure_main_settings(config_file, valid_lora_dir, use_presets, dpm_v2_patch, ui_config_file)\n",
        "\n",
        "    if use_gradio_auth:\n",
        "      cprint(\"Gradio Auth (use this account to login):\", color=\"green\")\n",
        "      cprint(\"[-] Username: cagliostro\", color=\"green\")\n",
        "      cprint(\"[-] Password:\", password, color=\"green\")\n",
        "      print_line(80, color=\"green\")\n",
        "    \n",
        "    config = {\n",
        "        \"enable-insecure-extension-access\": True,\n",
        "        \"disable-safe-unpickle\"           : True,\n",
        "        f\"{accelerator}\"                  : True,\n",
        "        f\"{select_tunnel}\"                : True if not select_tunnel == \"gradio\" and not ngrok_token else False,\n",
        "        \"share\"                           : True if not ngrok_token else False,\n",
        "        \"gradio-auth\"                     : f\"{user}:{password}\" if use_gradio_auth else None,\n",
        "        \"no-hashing\"                      : True,\n",
        "        \"disable-console-progressbars\"    : True,\n",
        "        \"ngrok\"                           : ngrok_token if ngrok_token else None,\n",
        "        \"ngrok-region\"                    : ngrok_region if ngrok_token else None,\n",
        "        \"opt-sub-quad-attention\"          : True,\n",
        "        \"opt-channelslast\"                : True,\n",
        "        \"no-download-sd-model\"            : True,\n",
        "        \"gradio-queue\"                    : True,\n",
        "        \"listen\"                          : True,\n",
        "        \"ckpt-dir\"                        : valid_ckpt_dir,\n",
        "        \"vae-dir\"                         : valid_vae_dir,\n",
        "        \"hypernetwork-dir\"                : valid_hypernetwork_dir,\n",
        "        \"embeddings-dir\"                  : valid_embedding_dir,\n",
        "        \"lora-dir\"                        : valid_lora_dir,\n",
        "        \"lyco-dir\"                        : valid_lora_dir,\n",
        "    }\n",
        "\n",
        "    args = parse_args(config)\n",
        "    final_args = f\"python launch.py {args} {additional_arguments}\"\n",
        "\n",
        "    cprint()\n",
        "    os.chdir(repo_dir)\n",
        "    !{final_args}\n",
        "\n",
        "main()\n",
        "\n"
      ],
      "metadata": {
        "id": "Oyrwg8cMyDXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title ## Remove Models, VAEs, and Output\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "for file in os.listdir(control_dir):\n",
        "    os.remove(os.path.join(control_dir, file))\n",
        "\n",
        "for file in os.listdir(vaes_dir):\n",
        "    os.remove(os.path.join(vaes_dir, file))\n",
        "\n",
        "for file in os.listdir(models_dir):\n",
        "    os.remove(os.path.join(models_dir, file))\n",
        "\n",
        "outputs_dir = [\n",
        "    \"/content/cagliostro-colab-ui/outputs/extras-images\",\n",
        "    \"/content/cagliostro-colab-ui/outputs/img2img-grids\",\n",
        "    \"/content/cagliostro-colab-ui/outputs/img2img-images\",\n",
        "    \"/content/cagliostro-colab-ui/outputs/txt2img-grids\",\n",
        "    \"/content/cagliostro-colab-ui/outputs/txt2img-images\",\n",
        "]\n",
        "\n",
        "for dir in outputs_dir:\n",
        "    if os.path.exists(dir):\n",
        "        for path in os.listdir(dir):\n",
        "            !rm -rf {os.path.join(dir, path)}\n",
        "     "
      ],
      "metadata": {
        "id": "Esyc3ANBUzcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaAJk33ppFw1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## **Start Cagliostro Colab UI** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#start-stable-diffusion-web-ui)</small></small>\n",
        "import os\n",
        "import random\n",
        "import string\n",
        "import torch\n",
        "from subprocess import getoutput\n",
        "\n",
        "%store -r \n",
        "\n",
        "# @markdown ### **Alternative Tunnel**\n",
        "\n",
        "# @markdown > `[Update]` Recommended Tunnels: `ngrok` > `gradio` > `cloudflared` > `remotemoe` > `localhostrun` > `googleusercontent`\n",
        "tunnel = \"multiple\" # @param ['none', 'multiple','cloudflared', 'localhostrun', 'remotemoe', \"googleusercontent\"]\n",
        "# @markdown > Get <b>your</b> token for ngrok [here](https://dashboard.ngrok.com/get-started/your-authtoken) \n",
        "ngrok_token = \"\" # @param {type: 'string'}\n",
        "ngrok_region = \"ap\" # @param [\"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "# @markdown ### **UI Config**\n",
        "use_dark_theme = True # @param {type: 'boolean'}\n",
        "theme = \"minimal_orange\" # @param [['moonlight', 'ogxRed', 'fun', 'ogxCyan', 'ogxCyanInvert', 'ogxBGreen', 'default_orange', 'tron2', 'd-230-52-94', 'minimal', 'ogxRedYellow', 'retrog', 'ogxRedPurple', 'ogxGreen', 'tron', 'default_cyan', 'default', 'backup', 'minimal_orange', 'Golde']\n",
        "# @markdown Set `use_preset` for using default prompt, resolution, sampler, and other settings\n",
        "use_presets = True # @param {type: 'boolean'}\n",
        "# @markdown ### **Arguments**\n",
        "use_gradio_auth = False # @param {type: 'boolean'}\n",
        "accelerator = \"xformers\" # @param ['xformers', 'opt-sdp-attention', 'opt-split-attention']\n",
        "if not \"T4\" in getoutput(\"nvidia-smi\") and not '2.0.1+cu118' in torch.__version__:\n",
        "    accelerator = \"opt-sdp-attention\"\n",
        "auto_select_model = False # @param {type: 'boolean'}\n",
        "auto_select_VAE = True # @param {type: 'boolean'}\n",
        "additional_arguments = \"--lowram --no-half-vae\" #@param {type: 'string'}\n",
        "\n",
        "voldemort=base64.b64decode((\"'c3RhYmxlLWRpZmZ1c2lvbi13ZWJ1aQ=='\").encode('ascii')).decode('ascii')\n",
        "\n",
        "user = \"cagliostro\"\n",
        "password = \"\".join(random.choices(string.ascii_letters + string.digits, k=6))\n",
        "\n",
        "def read_config(filename):\n",
        "    if filename.endswith(\".json\"):\n",
        "        with open(filename, \"r\") as f:\n",
        "          config = json.load(f)\n",
        "    else:\n",
        "        with open(filename, 'r') as f:\n",
        "          config = f.read()\n",
        "\n",
        "    return config\n",
        "\n",
        "def write_config(filename, config):\n",
        "    if filename.endswith(\".json\"):\n",
        "        with open(filename, \"w\") as f:\n",
        "            json.dump(config, f, indent=4)\n",
        "    else:\n",
        "        with open(filename, 'w', encoding=\"utf-8\") as f:\n",
        "            f.write(config)\n",
        "            f.close()  \n",
        "\n",
        "def open_theme(filename):\n",
        "    themes_folder = os.path.join(repo_dir, \"extensions-builtin/sd_theme_editor/themes\")\n",
        "    themes_file = os.path.join(themes_folder, f\"{filename}.css\")\n",
        "    webui_style_path = os.path.join(repo_dir, \"style.css\")\n",
        "\n",
        "    style_config = read_config(webui_style_path)\n",
        "    style_css_contents = style_config.split(\"/*BREAKPOINT_CSS_CONTENT*/\")[1]\n",
        "\n",
        "    theme_config = read_config(themes_file)\n",
        "    style_data = \":host{\" + theme_config + \"}\" + \"/*BREAKPOINT_CSS_CONTENT*/\" + style_css_contents\n",
        "    write_config(webui_style_path, style_data)\n",
        "\n",
        "def change_theme(filename):\n",
        "    try:\n",
        "        with capture.capture_output() as cap:\n",
        "            !git remote -v\n",
        "    except Exception as e:\n",
        "        print(f\"\u001b[1;32mAn error occurred: {e}\")\n",
        "\n",
        "    output = cap.stdout.strip()\n",
        "    if f\"https://github.com/anapnoe/{voldemort}-ux\" in output:\n",
        "        open_theme(filename)\n",
        "\n",
        "def is_dir_exist(cloned_dir, original_dir):\n",
        "    if os.path.exists(cloned_dir):\n",
        "        return cloned_dir \n",
        "    else:\n",
        "        return original_dir\n",
        "\n",
        "valid_ckpt_dir = is_dir_exist(os.path.join(fused_dir, \"model\"), models_dir)\n",
        "valid_vae_dir = is_dir_exist(os.path.join(fused_dir, \"vae\"), vaes_dir)\n",
        "valid_embedding_dir = is_dir_exist(os.path.join(fused_dir, \"embedding\"), embeddings_dir)\n",
        "valid_lora_dir = is_dir_exist(os.path.join(fused_dir, \"LoRA\"), lora_dir)\n",
        "valid_hypernetwork_dir = is_dir_exist(os.path.join(fused_dir, \"hypernetwork\"), hypernetworks_dir)\n",
        "\n",
        "if auto_select_model:\n",
        "    model_path = \"dummy.ckpt\"\n",
        "    models_list = os.listdir(valid_ckpt_dir)\n",
        "    model_files = [f for f in models_list if f.endswith(('.ckpt','.safetensors'))]\n",
        "    if model_files:\n",
        "        model_path = random.choice(model_files)\n",
        "        if os.path.exists(os.path.join(valid_ckpt_dir, model_path)):\n",
        "            config = read_config(config_file)\n",
        "            config[\"sd_model_checkpoint\"] = model_path\n",
        "            write_config(config_file, config)\n",
        "\n",
        "if auto_select_VAE:\n",
        "    vae_path = \"dummy.pt\"\n",
        "    vaes_list = os.listdir(valid_vae_dir)\n",
        "    vae_files = [f for f in vaes_list if f.endswith('.vae.pt')]\n",
        "    if vae_files:\n",
        "        vae_path = random.choice(vae_files)\n",
        "        if os.path.exists(os.path.join(valid_vae_dir, vae_path)):\n",
        "            config = read_config(config_file)\n",
        "            config[\"sd_vae\"] = vae_path\n",
        "            write_config(config_file, config)\n",
        "\n",
        "# config.json\n",
        "config = read_config(config_file)\n",
        "config[\"additional_networks_extra_lora_path\"] = valid_lora_dir\n",
        "config[\"CLIP_stop_at_last_layers\"] = 2\n",
        "config[\"eta_noise_seed_delta\"] = 0\n",
        "config[\"show_progress_every_n_steps\"] = 10\n",
        "config[\"show_progressbar\"] = True\n",
        "config[\"samples_filename_pattern\"] = \"[model_name]_[seed]\"\n",
        "if \"quicksettings\" in config:\n",
        "    config[\"quicksettings\"] = \"sd_model_checkpoint, sd_vae, CLIP_stop_at_last_layers, use_old_karras_scheduler_sigmas, always_discard_next_to_last_sigma\"\n",
        "elif \"quicksettings_list\" in config:\n",
        "    config[\"quicksettings_list\"] = [\"sd_model_checkpoint\", \"sd_vae\", \"CLIP_stop_at_last_layers\", \"use_old_karras_scheduler_sigmas\", \"always_discard_next_to_last_sigma\"]\n",
        "write_config(config_file, config)\n",
        "\n",
        "if use_presets:\n",
        "    # ui-config.json\n",
        "    default_prompt = \"masterpiece, best quality,\"\n",
        "    default_neg_prompt = \"(worst quality, low quality:1.4)\"\n",
        "    default_sampler = \"DPM++ 2M Karras\"\n",
        "    if dpm_v2_patch:\n",
        "        default_sampler = \"DPM++ 2M Karras v2\" \n",
        "    default_steps = 20\n",
        "    default_width = 512\n",
        "    default_height = 768\n",
        "    default_denoising_strength = 0.55\n",
        "    default_cfg_scale = 7\n",
        "\n",
        "    # txt2img\n",
        "    config = read_config(ui_config_file)\n",
        "    config[\"txt2img/Prompt/value\"] = default_prompt\n",
        "    config[\"txt2img/Negative prompt/value\"] = default_neg_prompt\n",
        "    config[\"txt2img/Sampling method/value\"] = default_sampler\n",
        "    config[\"txt2img/Sampling steps/value\"] = default_steps\n",
        "    config[\"txt2img/Width/value\"] = default_width\n",
        "    config[\"txt2img/Height/value\"] = default_height\n",
        "    config[\"txt2img/Upscaler/value\"] = \"Latent (nearest-exact)\"\n",
        "    config[\"txt2img/Denoising strength/value\"] = default_denoising_strength\n",
        "    config[\"txt2img/CFG Scale/value\"] = default_cfg_scale\n",
        "\n",
        "    # img2img\n",
        "    config[\"img2img/Prompt/value\"] = default_prompt\n",
        "    config[\"img2img/Negative prompt/value\"] = default_neg_prompt\n",
        "    config[\"img2img/Sampling method/value\"] = default_sampler\n",
        "    config[\"img2img/Sampling steps/value\"] = default_steps\n",
        "    config[\"img2img/Width/value\"] = default_width\n",
        "    config[\"img2img/Height/value\"] = default_height\n",
        "    config[\"img2img/Denoising strength/value\"] = default_denoising_strength\n",
        "    config[\"img2img/CFG Scale/value\"] = default_cfg_scale\n",
        "    write_config(ui_config_file, config)\n",
        "              \n",
        "os.chdir(repo_dir)\n",
        "change_theme(theme)\n",
        "\n",
        "if use_gradio_auth:\n",
        "      print(\"Gradio Auth (use this account to login):\")\n",
        "      print(\"- Username: cagliostro\")\n",
        "      print(\"- Password:\", password)\n",
        "      print(\"\\n\\n\")\n",
        "\n",
        "config = {\n",
        "    \"enable-insecure-extension-access\": True,\n",
        "    \"disable-safe-unpickle\": True,\n",
        "    f\"{accelerator}\": True,\n",
        "    f\"{tunnel}\": True if not tunnel == \"none\" and not ngrok_token else False,\n",
        "    \"share\": True if not ngrok_token else False,\n",
        "    \"gradio-auth\": f\"{user}:{password}\" if use_gradio_auth else None,\n",
        "    \"no-hashing\": True,\n",
        "    \"disable-console-progressbars\": True,\n",
        "    \"ngrok\": ngrok_token if ngrok_token else None,\n",
        "    \"ngrok-region\": ngrok_region if ngrok_token else None,\n",
        "    \"opt-sub-quad-attention\": True,\n",
        "    \"opt-channelslast\": True,\n",
        "    \"theme\": \"dark\" if use_dark_theme else \"light\",\n",
        "    \"no-download-sd-model\": True,\n",
        "    \"gradio-queue\": True,\n",
        "    \"listen\": True,\n",
        "    \"ckpt-dir\": valid_ckpt_dir,\n",
        "    \"vae-dir\": valid_vae_dir,\n",
        "    \"hypernetwork-dir\": valid_hypernetwork_dir,\n",
        "    \"embeddings-dir\": valid_embedding_dir,\n",
        "    \"lora-dir\": valid_lora_dir,\n",
        "    \"lyco-dir\": valid_lora_dir,\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python launch.py {args} {additional_arguments}\"\n",
        "\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Generated Images** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#download-generated-images)</small></small>\n",
        "# @markdown Download file manually from files tab or save to Google Drive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import drive\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(drive_dir)\n",
        "\n",
        "use_drive = True  # @param {type:\"boolean\"}\n",
        "folder_name = \"cagliostro-colab-ui\"  # @param {type: \"string\"}\n",
        "filename = \"waifu.zip\"  # @param {type: \"string\"}\n",
        "save_as = filename\n",
        "\n",
        "if os.path.exists(filename):\n",
        "    i = 1\n",
        "    while os.path.exists(f\"waifu({i}).zip\"):\n",
        "        i += 1\n",
        "    filename = f\"waifu({i}).zip\"\n",
        "\n",
        "!zip -r /content/outputs.zip .\n",
        "\n",
        "if use_drive:\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "\n",
        "    def create_folder(folder_name):\n",
        "        file_list = drive.ListFile(\n",
        "            {\n",
        "                \"q\": \"title='{}' and mimeType='application/vnd.google-apps.folder' and trashed=false\".format(\n",
        "                    folder_name\n",
        "                )\n",
        "            }\n",
        "        ).GetList()\n",
        "        if len(file_list) > 0:\n",
        "            print(\"Debug: Folder exists\")\n",
        "            folder_id = file_list[0][\"id\"]\n",
        "        else:\n",
        "            print(\"Debug: Creating folder\")\n",
        "            file = drive.CreateFile(\n",
        "                {\"title\": folder_name, \"mimeType\": \"application/vnd.google-apps.folder\"}\n",
        "            )\n",
        "            file.Upload()\n",
        "            folder_id = file.attr[\"metadata\"][\"id\"]\n",
        "        return folder_id\n",
        "\n",
        "    def upload_file(file_name, folder_id, save_as):\n",
        "        file_list = drive.ListFile(\n",
        "            {\"q\": \"title='{}' and trashed=false\".format(save_as)}\n",
        "        ).GetList()\n",
        "        if len(file_list) > 0:\n",
        "            print(\"Debug: File already exists\")\n",
        "            i = 1\n",
        "            while True:\n",
        "                new_name = (\n",
        "                    os.path.splitext(save_as)[0]\n",
        "                    + f\"({i})\"\n",
        "                    + os.path.splitext(save_as)[1]\n",
        "                )\n",
        "                file_list = drive.ListFile(\n",
        "                    {\"q\": \"title='{}' and trashed=false\".format(new_name)}\n",
        "                ).GetList()\n",
        "                if len(file_list) == 0:\n",
        "                    save_as = new_name\n",
        "                    break\n",
        "                i += 1\n",
        "        file = drive.CreateFile({\"title\": save_as, \"parents\": [{\"id\": folder_id}]})\n",
        "        file.SetContentFile(file_name)\n",
        "        file.Upload()\n",
        "        file.InsertPermission({\"type\": \"anyone\", \"value\": \"anyone\", \"role\": \"reader\"})\n",
        "        return file.attr[\"metadata\"][\"id\"]\n",
        "\n",
        "    file_id = upload_file(\"/content/outputs.zip\", create_folder(folder_name), save_as)\n",
        "    print(\n",
        "        \"Your sharing link: https://drive.google.com/file/d/\"\n",
        "        + file_id\n",
        "        + \"/view?usp=sharing\"\n",
        "    )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ojb4nAieATxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extras"
      ],
      "metadata": {
        "id": "4SUHPtGLz2m4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **Download Generated Images V2** <small><small>[Cheatsheet](https://github.com/Linaqruf/sd-notebook-collection/blob/main/MANUAL.md#download-generated-images-v2)</small></small>\n",
        "from IPython.utils import capture\n",
        "from huggingface_hub import login\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# @markdown Download your output by upload it to **Huggingface** instead of Google Drive.\n",
        "# @markdown > Get **your** huggingface `WRITE` token [here](https://huggingface.co/settings/tokens)\n",
        "write_token = \"\"  # @param {type:\"string\"}\n",
        "# @markdown Specify where is your repo located, it will automatically create your repo if you didn't have one.\n",
        "repo_name = \"cagliostro-colab-ui\"  # @param{type:\"string\"}\n",
        "repo_name = repo_name.replace(\" \", \"-\")\n",
        "private_repo = False  # @param{type:\"boolean\"}\n",
        "# @markdown This will be compressed to zip and uploaded to datasets repo\n",
        "project_name = \"waifu\"  # @param {type :\"string\"}\n",
        "project_name = project_name.replace(\" \", \"_\")\n",
        "\n",
        "if not project_name:\n",
        "    project_name = \"waifu\"\n",
        "\n",
        "dataset_zip = project_name + \".zip\"\n",
        "output_path = os.path.join(root_dir, dataset_zip)\n",
        "commit_message = \"Feat: Upload \" + dataset_zip + \" with Cagliostro Colab UI\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    login(write_token, add_to_git_credential=True)\n",
        "output = cap.stdout.strip()\n",
        "if \"Token is valid.\" in output:\n",
        "    print(\"\u001b[1;32mLogin Succesful.\")\n",
        "\n",
        "api = HfApi()\n",
        "user = api.whoami(write_token)\n",
        "\n",
        "datasets_repo = user[\"name\"] + \"/\" + repo_name.strip()\n",
        "\n",
        "if repo_name:\n",
        "    try:\n",
        "        validate_repo_id(datasets_repo)\n",
        "        api.create_repo(\n",
        "            repo_id=datasets_repo, repo_type=\"dataset\", private=private_repo\n",
        "        )\n",
        "        print(\n",
        "            f\"\u001b[1;32mRepo created, located at https://huggingface.co/datasets/{datasets_repo}\"\n",
        "        )\n",
        "\n",
        "    except HfHubHTTPError as e:\n",
        "        print(f\"\u001b[1;32mRepo exist, skipping...\")\n",
        "\n",
        "os.chdir(drive_dir)\n",
        "print(f\"\u001b[1;32mCompressing to ZIP...\")\n",
        "with capture.capture_output() as cap:\n",
        "    !zip -rv {output_path} .\n",
        "\n",
        "print(f\"\u001b[1;32mUploading generated images... Please wait...\")\n",
        "\n",
        "api.upload_file(\n",
        "    path_or_fileobj=output_path,\n",
        "    path_in_repo=dataset_zip,\n",
        "    repo_id=datasets_repo,\n",
        "    repo_type=\"dataset\",\n",
        "    commit_message=commit_message,\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"\u001b[1;32mUpload success, download directly at https://huggingface.co/datasets/{datasets_repo}/resolve/main/{dataset_zip}\"\n",
        ")\n",
        "\n",
        "os.remove(output_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EGXqJLXwnJQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}